{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 11: Feature Engineering & Cross-Validation\n",
    "\n",
    "In this lab, you will gain practice with using the scikit learn library to do some feature engineering and how to use cross-validation to produce a model with the least error for new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "Assignment: Lab 11\n",
      "OK, version v1.13.9\n",
      "=====================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "from IPython.display import display, Latex, Markdown\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('lab11.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "For this lab, we will be using a toy dataset to predict the house prices in Boston with data provided by the `sklearn.datasets` package.\n",
    "\n",
    "Run the following cell to load the data. This will return a dictionary object which includes keys for:\n",
    "    - `data` : the data to learn\n",
    "    - `target` : the response vector\n",
    "    - `feature_names`: the column names\n",
    "    - `DESCR` : a full description of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'feature_names', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston_data = load_boston()\n",
    "print(boston_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A look at the `DESCR` attribute tells us the data contains these features:\n",
    "\n",
    "    1. CRIM      per capita crime rate by town\n",
    "    2. ZN        proportion of residential land zoned for lots over \n",
    "                 25,000 sq.ft.\n",
    "    3. INDUS     proportion of non-retail business acres per town\n",
    "    4. CHAS      Charles River dummy variable (= 1 if tract bounds \n",
    "                 river; 0 otherwise)\n",
    "    5. NOX       nitric oxides concentration (parts per 10 million)\n",
    "    6. RM        average number of rooms per dwelling\n",
    "    7. AGE       proportion of owner-occupied units built prior to 1940\n",
    "    8. DIS       weighted distances to five Boston employment centres\n",
    "    9. RAD       index of accessibility to radial highways\n",
    "    10. TAX      full-value property-tax rate per 10,000 USD\n",
    "    11. PTRATIO  pupil-teacher ratio by town\n",
    "    12. B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks \n",
    "                 by town\n",
    "    13. LSTAT    % lower status of the population\n",
    "    \n",
    "Let's now convert this data into a pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = pd.DataFrame(boston_data.data, columns=boston_data.feature_names)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Let's train some data! Before we can do this however, we need to split our data into a training set and validation set. These hold out points will be used to choose our best model. Additionally, remember that the response vector (housing prices) lives separate of the data in the `target` attribute.\n",
    "\n",
    "Use the [`train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function to split out one third of the training data for validation. Call the resulting datasets `X_train`, `X_test`, `Y_train`, `Y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339, 13)\n",
      "(167, 13)\n",
      "(339,)\n",
      "(167,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ksab77/anaconda3/envs/ds100/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "\n",
    "X = boston\n",
    "Y = pd.Series(boston_data.target)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, train_size=0.67)[0], train_test_split(X, train_size=0.67)[1], train_test_split(Y, train_size=0.67)[0], train_test_split(Y, train_size=0.67)[1]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "test",
     "q01"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving notebook... Saved 'lab11.ipynb'.\n",
      "Backup... 100% complete\n",
      "Backup successful for user: sungbin.andy.kang@berkeley.edu\n",
      "URL: https://okpy.org/cal/ds100/fa17/lab11/backups/48R3D0\n",
      "NOTE: this is only a backup. To submit your assignment, use:\n",
      "\tpython3 ok --submit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = ok.grade('q01')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "As a warmup, let's regress a line to this data using `sklearn`. We've imported `sklearn.linear_model` as lm, so you can use that instead of typing out the whole module name. Running the cell should create a scatter plot for our predictions vs the true prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Prices vs Predicted prices')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEhCAYAAABlUDcAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3XlcVOX+B/DPzLANO4MoKAqKgoii\niOFu5i1zQUr7mZaamZqWmbfUTK+pLWbGVbNc7i2zstTUq5lSalmRmqSmpKm4saMg67AOA8yc3x80\nAwNnZs4MZ/bv+/XqlZ6ZOec5jzPn++yPgGEYBoQQQkgLQksngBBCiHWiAEEIIYQVBQhCCCGsKEAQ\nQghhRQGCEEIIKwoQhBBCWFGAsGMfffQRIiIi1P8NHDgQTz31FJKTkzl9/vXXX8cjjzxi2kRagUOH\nDmnkU2xsLCZNmoTDhw+b/NrfffcdIiIikJeXpz4WERGBbdu2GXSejz76CBcuXOA1batWrcKoUaN4\nPSebUaNG4V//+pfJr0MM52TpBBDTEolE2LNnDwCguLgYn332GebNm4edO3di6NChOj/74osvorq6\n2hzJtArbt2+HRCJBeXk5Dhw4gGXLlqGurg5PPvmkWdOxb98+BAUFGfSZLVu2QCQS4YEHHjBRqkxn\ny5Yt8PLysnQyCAsKEA6gX79+6j8PGjQII0eOxJdffqk1QNTW1sLNzQ1dunQxVxKtQq9evRAYGAgA\nGDp0KMaPH48vv/xSa4BQ5RPfmv972TNV/vXq1cvSSSFaUBOTg/H09ERoaChyc3MBAOfOnUNERARO\nnjyJxYsXY8CAAZg7dy4A9iamqqoqvPvuu3jooYfQu3dvjBw5EsuXL9d4z9WrVzFnzhzExsaiX79+\nmD17Nm7fvq3xnm+++QYTJkxA3759MWDAAEyaNAknT57Umu6VK1di1KhRaDnxPysrCxERETh27BgA\nID09HfPnz8fAgQMRHR2NUaNG4a233jI4n5ycnNCzZ091PuXl5SEiIgL79u3Dm2++iUGDBmHcuHEG\n3XN1dTVWrFiB2NhYxMXFYc2aNaitrW11bbYmpitXrmDu3LkYMGAA+vXrh8cffxxJSUnq9wPA5s2b\n1c1khw4dUn/2+++/x6RJkxAdHY2BAwdixYoVKC8v1zh/ZmYmZs6ciejoaDz00EPYtWsXp3xSNc9d\nvHgRs2fPRr9+/TB8+HDs2LFD430fffQRevXqhbS0NDz99NOIjo7GJ598AoC9iSkzMxOLFi1S/zuO\nHTsWX3zxhcZ79N1XfX09NmzYgFGjRqF3794YPHgwZs6ciczMTE73RqgG4XAUCgUKCgoQHh6ucfzN\nN9/E2LFj8eGHH7Z6CKvU1dVh5syZyM7OxgsvvIBevXqhuLgYP/zwg/o9f/31F6ZNm4YHHngA7733\nHoRCIXbs2IHp06fjyJEj6NChAy5cuIDXX38dzz77LFasWIG6ujrcvHkTFRUVWtM9YcIEHDhwAJcu\nXUJsbKz6+NGjR+Hp6aluK583bx78/PzwzjvvwNvbG/fu3cOff/5pVF7l5eWhQ4cOGsc++ugjDBky\nBImJiaivr+d8z0BjkPvll1/wz3/+E926dcM333yDDz/8UG86UlNT8cwzzyAyMhJvvvkm/Pz8cPPm\nTdy7dw9AY5PUlClTMGXKFEyaNAkA1LW/3bt345133sFTTz2FV155BcXFxdi4cSMyMjKwZ88eCIVC\n1NXVYfbs2RAKhXj33Xfh6uqKbdu2obS0FCKRiFNeLVmyBJMmTcKsWbOQnJyMxMRE+Pj4YPLkyer3\nMAyDl19+GdOnT8fChQu1Nivl5OTgySefhL+/P15//XUEBgYiMzNTHay53td///tffPXVV1i8eDHC\nw8NRUVGBixcvorKyktM9EQAMsVsffvghExkZydTX1zP19fXM/fv3mdWrVzPh4eHM/v37GYZhmN9/\n/50JDw9nli5d2urzy5YtYx5++GH13/fv38+Eh4czZ8+e1XrNGTNmMBMnTmQaGhrUxyorK5m4uDhm\n/fr1DMMwzI4dO5gHHnjAoHtRKpXMiBEjmDVr1mgcHz16NPP6668zDMMwJSUlTHh4OHPy5EmDzn3w\n4EEmPDycycvLY+rr65mSkhJm69atTHh4OLNx40aGYRgmNzeXCQ8PZ6ZNm2bUPd+5c4eJiIhgvvrq\nK43PTpo0iQkPD2dyc3PVx8LDw5mtW7eq/z516lTmkUceYeRyudZ7aPkZhmGYqqoqJiYmhnnnnXc0\njv/xxx9MeHg4k5yczDAMw+zdu5cJDw9nbt68qX5PcXExEx0dzTz00ENar8kwTXmnuk+Vl19+mXnw\nwQcZhULBMEzjdzE8PJw5cOBAq3M89NBDzIoVK9R/X7x4MTNgwACmrKyM9Zpc7+v5559nFixYoDP9\nRDdqYrJzCoUCUVFRiIqKwvDhw/Htt99i4cKFGiU7AHjooYf0nuvs2bPo1KkTBg8ezPp6bW0t/vjj\nD4wZMwYMw6ChoQENDQ1wc3NDTEwMLl26BACIiopCeXk5li5dit9++41TR7hAIMC4ceNw/PhxNDQ0\nAGhsdsnKysKECRMAAH5+fujUqRM2btyIQ4cO4e7du3rP29yoUaMQFRWFwYMHY9u2bZg+fToWLFig\n8Z6RI0cadc9XrlwBwzCtmuzGjBmjM00ymQx//vknEhIS4OLiYtD9/Pnnn6iursa4cePU6WpoaEDf\nvn3h6emJixcvAgAuX76M0NBQjVqlv78/4uLiOF+r5X09+uijyM/Px/379zWOcxkVlZKSgocffhi+\nvr5tuq/evXvj119/xebNm3HlyhX194ZwR01Mdk4kEmHfvn0QCATw8fFBx44dWZsNAgIC9J5LKpW2\nanJprry8HAqFAhs2bMCGDRtavR4aGgqgsaN848aN2LVrF+bOnQuhUIiRI0dixYoV6Nixo9bzJyQk\nYOfOnfjtt9/w4IMP4ujRowgICMDAgQMBNAaRzz77DJs3b8batWtRVVWF7t2745///Cen4boff/wx\nJBIJvLy80LFjR9YHcrt27Yy656KiIgCND15d52upoqICSqVSZ75rU1JSAgCYOnUq6+tSqRQAUFhY\n2CpdqrSlp6dzupa2+yosLFSPyBIKhZBIJHrPJZVK0b59e62vc72vefPmQSQS4dtvv8W2bdvg4+OD\niRMn4pVXXjHJ4AJ7RAHCAfTp04eX8/j5+elsz/fy8oJQKMSzzz6r0YGr4urqqv7z+PHjMX78eFRV\nVeHXX3/FunXrsHTpUuzevVvr+SMjI9G9e3ckJSVh2LBhOHbsGMaPH68R8EJCQrBx40YolUpcvXoV\n27Ztw6JFi/Ddd9+ha9euOu8vIiJCPYpJG4FAYNQ9qwJwSUmJxsOvuLhY5/W8vb0hFApblcS5UJXA\nN27cyDoiTfWwbt++vbqm05y+tDVXUlKicQ3VZ5sXPFrmnTZ+fn4oLCzU+jrX+3JxccGLL76IF198\nEffv30dSUhI2btwId3d3LFq0iFNaHB01MRHOBg8ejLt37+L3339nfd3d3R2xsbG4desW+vTp0+q/\nlh3jQOOoKlWwaDnqh018fDxOnjyJX375BUVFRermpZaEQiGio6Pxz3/+EwqFAhkZGYbdLEdc7zk6\nOhoCgQA//vijxuePHz+u8/xisRgxMTE4cuQI6urqtL7P2dkZcrlc41j//v3h7u6OvLw81rR16tRJ\nnbasrCyN/C8pKcH58+c550PL+zpx4gQCAwP1Blw2gwcPxsmTJ9U1gZa43ldzHTp0wOzZsxEeHs7p\ne0YaUQ2CcPbYY49h7969eOmll/Diiy8iMjISZWVlOHHiBDZv3gwAWLZsGWbMmIF58+bh8ccfh7+/\nP4qLi5GamoqQkBBMnz4dH374IUpKSjBw4EAEBAQgOzsbR44c0TtxD2gMEB988AHeeustdO3aFb17\n91a/duPGDaxbtw7jxo1Dly5dIJfL8eWXX8LLywt9+/Y1Wb5wueewsDA8+uijSExMRENDA7p27Ypv\nvvlG3fSky5IlS/DMM89gxowZeOaZZyCRSHD79m3U1tbi+eefBwCEhYXh559/xqBBg+Dp6Yng4GD4\n+flhyZIlWLduHYqKijB06FC4ubkhPz8fv/32G6ZNm4b+/ftj0qRJ+O9//4sXXngBr7zyClxcXNRN\nMlwdO3YM7u7u6NevH5KTk3H8+HG89dZbEAoNL4MuXLgQycnJmDp1KubNm4egoCDk5OQgKysLr732\nGjw9PTndl2qkXa9eveDp6Yk//vgDN2/eNPvER1tGAYJw5uLigi+++AIffPABPvvsM5SVlaFdu3YY\nMmSI+j19+vTBvn37sGXLFqxZswY1NTUICAhA37591aX96OhofPHFF/jxxx9RUVGB9u3bY8KECXj5\n5Zf1pqFz586IiYlBampqq/cHBASgQ4cO2LFjB+7fvw+xWIw+ffpg586detv624LLPQPA2rVrsXbt\nWmzevBkikQhjx47FokWLsGLFCp3n79+/P3bv3o3Nmzdj5cqVABqb0lTBAWgcQvv2229j7ty5qK+v\nx7p16zBp0iRMmzYNgYGB+PTTT3Hw4EEAQGBgIIYMGYLg4GAAjc1gn376Kd588028/vrrkEgkmDVr\nFjIyMnDmzBlOeZCYmIht27bhk08+gZeXFxYvXowpU6YYlI8qXbp0wddff41Nmzbh3XffhVwuR3Bw\nMJ566in1e7jc14ABA3Ds2DHs2rUL9fX1CA4OxvLlyzXOQ3QTMAxtOUoIMc6hQ4ewfPly/Prrr0Y1\nJxHrRn0QhBBCWFGAIIQQwoqamAghhLCiGgQhhBBWdjWKqajIthfhEggE8Pf3QElJtdYF8xwJ5UcT\nygtNlB9N+MiLgAD2hROpBmFFhMLGf2wjho7bJcqPJpQXmig/mpgyLyh7CSGEsKIAQQghhBUFCEII\nIawoQBBCCGFFAYIQLYqkMlzPLEWRVGbppBBiEXY1zJUQPqRllyLpbDayCiogkysgdhUhNNAb8UNC\nEBmif8MbQuwFBQhCmknLLsWOpDSUVTbtrSCTK5CWXYaC0hrMiY+kIEEcBjUxEdJM0tlsjeDQXFml\nHEkp2WZOESGWQwGCkL8VSmXIzK/Q+Z6s/ArqkyAOgwIEIX8rLpOhtk6h8z0yuQLF5RQgiGOgAEHI\n39r5ieHmItL5HrGrCO18xGZKESGWRQGCkL+19xWja5C3zveEBnkjwJcCBHEMFCAIaSZ+SAj8vFxZ\nX/PzckX84BAzp4gQy6EAQUgzkSGSxqGsoX4QuzY2N4ldRYgM9aMhrsTh0DwIQlqIDJEgMkSCIqkM\nxeUytPMRU7MScUgUIAjRIsCXAgNxbNTERAghhBUFCEIIIawoQBBCCGFFAYIQQggrChCEEEJYUYAg\nhBDCigIEIYQQVhQgCCGEsKIAQQghhBUFCEIIIawoQBBCCGFFAYIQQggrChCEEEJYUYAghBDCigIE\nIYQQVhQgCCGEsKIAQQghhBUFCEIIIawoQBBCCGFFAYIQQggrJ3NdKDExEcnJycjPz4e7uztGjhyJ\nJUuWwNfXV/2enJwcrF+/Hr///jsAICwsDLt374azs7O5kkkIIeRvZqtBiEQiJCYm4ty5czhy5AgK\nCgqwfPly9eulpaV4+umn0bNnTyQnJ+P8+fN44403IBKJzJVEQgghzZitBvHqq6+q/yyRSDB9+nQs\nXrxYfeyzzz5Dx44dsXDhQvWxPn36GHQNgUAAoQ03mgmFAo3/OzrKjyaUF5ooP5qYMi/MFiBaSklJ\nQUREhPrv586dQ0hICF544QVcvHgRHTp0wNy5c5GQkMD5nP7+HhAIbP8L4+vrYekkWBXKjyaUF5oo\nP5qYIi8sEiBOnDiB/fv346uvvlIfKysrw19//YVNmzbho48+wrlz5zB//nx07NgRAwYM4HTekpJq\nm69B+Pp6QCqthlLJWDo5Fkf50YTyQhPlRxM+8kIi8WQ9bvYAcezYMaxevRrbt29HVFSU+riHhwf6\n9euHMWPGAACGDh2K4cOH4+eff+YcIBiGgUJhkmSblVLJQKFw7C99c5QfTSgvNFF+NDFFXpi1vH3w\n4EF1cBg0aJDGa5GRkazNQ/bQZEQIIbbIbAFi165deP/997Fjxw7Exsa2en3KlCm4fPkyTp48CaVS\nid9//x2//fYbHn74YXMlkRBCSDMChmHMUj+LiIiAk5MTXFxcNI6npqaq/3zs2DF88MEHuH//PoKD\ng7FgwQKMHTuW8zWKiip5S68liEQCSCSeKC2tomozKD+ao7zQRPnRhI+8CAjwYj1utj6Imzdv6n3P\n2LFjDQoIhBBCTMeGx/wQQggxJQoQhBBCWFGAIIQQwooCBCGEEFYUIAghhLCiAEEIIYQVp2GuRUVF\nAICAgAAAwI0bN/Dtt9+ie/fueOKJJ0yXOkIIsUFFUhmKymQI8BMjwFds6eQYjVOAePXVV5GQkIDJ\nkyejrKwMM2bMQEBAAPbt24fS0lLMnTvX1OkkhBCrl5ZdiqSz2cgqqIBMroDYVYTQQG/EDwlBZIjE\n0skzGKcmplu3bqFfv34AgJMnT6Jz5874/vvvsX79evzvf/8zaQIJIcQWpGWXYkdSGtKyyyCTN64a\nKpMrkJZd9vfxUgun0HCcAoRMJoOHR+Na47///jv+8Y9/AAB69+6NgoIC06WOEEJsRNLZbJRVyllf\nK6uUIykl28wpajtOAaJTp044f/48ampqcPbsWQwcOBBA4zahqsBBCCGOqlAqQ2Z+hc73ZOVXoEgq\nM1OK+MEpQMycORMrVqzAgw8+iKCgIPVqrBcuXECPHj1MmkBCCLF2xWUy1Nbp3oxGJleguNy2AgSn\nTuqpU6ciKioK9+/fx5AhQ9R7NISEhODll182aQIJIcTatfMTw81FpDNIiF1FaOdjWyOaOK/m2qdP\nH/Tp00fj2EMPPcR7ggghxNa09xWja5A30rLLtL4nNMjb5oa8cp4ot3//fkyYMAF9+/ZFbm4uAODj\njz/G999/b7LEEUKIrYgfEgI/L1fW1/y8XBE/OMTMKWo7TgFiz5492LhxIyZMmIDm+wu1b98ee/bs\nMVniCCHEVkSGSDAnPhKRoX4Qu4oANDYrRYb6NR63wXkQnJqYdu/ejXfeeQcPP/wwtm/frj7eq1cv\n3Llzx2SJI4QQWxIZIkFkiARFUhmKy2Vo5+MAM6lzc3MRGRnZ6rirqytqamp4TxQhhNiyAF/bDgwq\nnJqYgoKCWGsKKSkpCA0N5TtNhBBCrACnGsRTTz2Fd955B87OzgCArKwsnD59Gps2bcLSpUtNmkBC\nCCGWwSlAPPvssygvL8eLL76I2tpazJ07F66urpg7dy6efPJJU6eREEKIBXCeB7Fo0SLMmzcPt2/f\nBsMw6N69O9zd3U2ZNkIIIRbEKUDU1dWBYRi4ublpTJaTy+UQCARwcXExWQIJIYRYBqdO6kWLFmHv\n3r2tju/duxevvPIK74kihBBieZwCRGpqKoYOHdrq+JAhQ5Camsp7ogghhFgepwBRU1MDJ6fWrVFO\nTk6oqqriPVGEEEIsj1OACAsLw8mTJ1sd/+mnn2geBCGE2ClOndTPPfccli9fjqKiIgwZMgRA4yS5\nPXv24O233zZpAgkhhFgGpwAxYcIE1NbWYuvWrdi1axcAoEOHDnjjjTfw+OOPmzSBhBBCLIPzPIjJ\nkydj8uTJKC1t3HhbIrG9lQkJIYRwxzlAqFBgIIQQx6A1QDz33HPYvHkzvLy88Nxzz+k8yc6dO3lP\nGCGEEMvSGiA6dOig3nu6ffv26j8TQghxDAKm+RZxWiiVSgiFnHcntZiiokpLJ6FNRCIBJBJPlJZW\nQaHQ+89i9yg/mlBeaKL8aMJHXgQEeLEe1/vUr6urQ+/evXHr1i2jLkyILSqSynA9sxRFUpmlk0KI\nxejtpHZxcUFgYCA4VDQIsXlp2aVIOpuNrIIKyOQKiF1FCA30RvyQEJvcU5iQtuDUbvTss89i69at\nqK2tNXV6iJ3gqwReUFKNa5klWs/DZ0k/LbsUO5LSkJZdBplcAQCQyRVIyy77+3hpm69BiC3hNMz1\nl19+weXLlzFixAiEhYVBLNbca5VGMREVvkrgadml+C4lG1kFlaipbWh1HlOU9JPOZqOsUs76Wlml\nHEkp2VSLIA6FU4AIDAxEYGCgqdNCbJyqBN78IasqgReU1mBOfCSnB6y+8zzyQDB+vJCn9zpFUhmK\nymQI8NO/gXyhVIbM/Aqd78nKr0CRVGYXm9ETwgWnALFu3TpTp4PYAb5K4HrPczYbNbUNWl/f9/Nt\neLi5GFS7KC6TobZOoTNdMrkCxeUUIIjjMGgmdU5ODtLT0yEQCBAWFobOnTubKl3ExvBVAudyHm3B\nQSXnfjWAavXfudRi2vmJ4eYi0hkkxK4itPOh4EAcB6dOaqlUigULFmD06NF44YUXMH/+fIwePRov\nvfQSysvLOV0oMTER48ePR//+/TFs2DCsXLkSUqlU63sjIiLw7bffcr8TYlGGlMDbeh5jqWoxbNr7\nitE1yFvn50ODvKn2QBwKpwCxatUq3LlzB59++ilSU1ORmpqKHTt24Pbt21i1ahWnC4lEIiQmJuLc\nuXM4cuQICgoKsHz58lbvu3LlCk6dOoWAgADD7oRYlKoErguXEjiX87RFel45buaUsb4WPyQEfl6u\nrK/5ebkifnCIydJFiDXi1MR06tQpfPLJJ3jggQfUx4YOHYp33nkHzz//PKcLvfrqq+o/SyQSTJ8+\nHYsXL9Z4T11dHf71r3/hrbfeavUaFwKBADYw4VsroVCg8X9bEuTvjm4dvXE9i/3hCwBdg7wR6O/e\n5vO4uznpbWbSpq5BiU37/0T3YF8kDA1FZGhTc1Pvbv54fkIvHD2bhcz8pv6LrkHerd5rbrb83TAF\nyo8mpswLTgHCy8sLfn5+rY77+vrCw8PDqAunpKQgIiJC49hHH32EgQMHIiYmxqhz+vt72MWaUb6+\nxuWppU0bE4mNey+hpLz1fBl/HzdMGxMJicSzzed5fEQYDp9KZ32di7oGBtezynC/TIZXnuqPvj2a\naqvDJJ4YFtsFBSXVKCytQXuJOwL9reffw1a/G6ZC+dHEFHnBKUDMmjULGzduxPvvvw9Pz8YfeHV1\nNTZv3oxZs2YZfNETJ05g//79+Oqrr9TH/vrrLxw/fhyHDx82+HwqJSXVNl+D8PX1gFRaDaXS9mau\nB/uLMWd8pNYSeLC/GKWl+vcwD/YX4/8e7IYT53Nwv0zGWpJv5+XCep1qWT2y73PbJ72kvBZ7jqeh\ns3/rZi8XQWM6AIZTmk3N1r8bfKP8aMJHXmgruHEKEKdPn8aVK1cwYsQIdO/eHQDUo5lqamrw22+/\nqd+rb9LcsWPHsHr1amzfvh1RUVEAGpuWVqxYgVWrVhldIwEAhmGgME3/plkplYzNLkAW0cUPEV38\nUCSVobhchnY+TXMQuNxTywlwbi4idOngiUfjOmNwVJD6PNquwzaHQpfM/AoUlNTYTOezLX83TIHy\no4kp8sLoiXJhYWEGX+zgwYNYv349tm/fjtjYWPXxwsJC3L59G0uWLFEfq6iowJo1a3Dq1Cls2LDB\n4GsRywrw1T85rSW2h3ttnQI596vwv+QM+Hq6thqi2vI6kSESzImPRFJKNtLzylHXoNR5TZrbQIh2\nZpsot2vXLmzduhU7duxAdHS0xmtBQUFITk7WODZlyhTMmTMH8fHxbb42sQ18TbSLDJEgMkSCGzll\n2LTvT9TrKFXR3AZCtDN4y1FjrV27Fk5OTpg5c6bG8dTUVIhEolY1FJFIBG9vb9bOcWJ/TLHURc8u\nfuge7Iu0bO0jomhuAyHamS1A3Lx506D3//zzzyZKCbFGplrqIn5ICApKa1hrJjS3gRDdbHjMD7En\nfEy0Y1v6W9UnERnqB7GrSH2eyFA/zosHEuKozFaDIEQX1VIXxjQH6Vv6W/Uf28gqQoh2FCCI1TCm\nOciQJcaNGVlFiCPTGiAMmbD2+OOP85IY4tiaD1HN+nsCnLubE0IDvTB+MPtS3bTJDyGmozVA/Otf\n/9L4O8MwUCo1x5QLhUIIhUIKEIQ3zZuDSitr0T3EHy4C9glAhVIZ7uSxrwisom3kkyGbCRHiqLQG\niGvXrqn/fPbsWSQmJmLJkiXo378/AODSpUvYsGGDUYvqEaJPgK8Ygf7ukEg8tC51cfFGoc45DkDr\nkU+m2KqUEHvFeaLcqlWrWq3m6uLigjVr1uC7774zWQKJbo5cEr50u0jve5qPfOJrS1RCHAWnAJGd\nna11Ndfc3FzeE0X0c/SScKFUhrtF1Xrf17GdhzpwUn8FIYbhNA8iIiICmzZtQlVVU1W/uroaH3zw\nQaslu4npqUrCadllkMkbJ5epSsKNx0stnELT47rzXGxE41LehszUJoQ04lSDWL16NebNm9dqNVc3\nNzd8/PHHJk0gaY1Kwtz2kHZ1EiI2vD0A083UJsSecQoQvXv3xsmTJ3HkyBFkZGQAACZPnoz4+HiI\nxfRjMidTrFlki7hMrOsW7KPOAy4BhW2mtqqPRyQSQKFgHLKvhzguzhPlxGIxpkyZYsq0EA6oJNzE\nkIl1hs7UVvXxpN+Voq6haaSUq7MQ3Tr6OExfD3FsnNdi+u233zB//nyMGzcO+fn5AID9+/cjJSXF\nZIkjrfGxZpGpsK2FZEqGrrMUPyQEfl6urOdqHlCa9/E0Dw4AIK9XOlRfD3FsnGoQx48fx7Jly/DY\nY4/h7NmzaGho3DBeoVBgx44dGDx4sEkTSZq0Zc0iU7HkiCpD1llim6ktdhUhNMgb8c1mauvq41Fx\nlL4e4tg4BYj//ve/WLNmDSZOnIijR4+qj/fr1w9btmwxWeIIO2tawtpa5hZwXWdJX0Dh0sej4gh9\nPcSxcWpiysjIQFxcXKvjnp6eqKjg9mMi/LGmJay5jKiyRgG+YkSGSFo93LkOnwWa+noIsVecahD+\n/v64e/cuOnXqpHH88uXL6Nixo0kSRnSzhiWs7XFEFZfRTiq0XalhHHnWv63iFCAmTJiA9957D5s2\nbYJAIEBtbS1+/fVXvP/++5g+fbqp00h00Ne0YsofpT2OqOLSx6NC25Vy4+iz/m0ZpwCxcOFC5Ofn\n49FHHwUAJCQkAGhc5nvOnDlY44vqAAAgAElEQVSmSx0xWssfpauLEO193TFmYGcMjgri5RrGzi2w\ndrr6eFRM1ddjb6Vsa+mjIsbhFCCcnJzw/vvvY+HChbh27RqUSiWioqIQEkL7+Vojth+lvE6J3MIq\nfHI0DSfO52LKqO5t/mFa44gqPjQf7ZSe12IehJMQ3YJ9NEY98cFeS9k069+2cQoQW7ZswezZs9G5\nc2d07txZfby2thY7duzASy+9ZLIEEsPpG6aZc78KO5LSeCm9WdOIKj617OMRCgRQMoxJ+nq4lLJ7\nd/Pn9ZrmYI99VI6G0yimrVu3oqamptVxmUyGrVu38p4oYrxCqQwZ98r1vo+vEUbWNKLKFFSjnSK6\n+LGOeuKDrY4E08eQPipinTjVIBiGgUAgaHU8NzcX3t7evCeKGCctuxRf/3QH8nql/jeDv9KbNYyo\nslWGlLIlEk8zpYof9tpH5Uh0BohRo0ZBIBBAIBDgiSeegFDYVOFQKpUoKirCuHHjTJ5Ioh9bM4U+\nfI8w4jpZjTThWsoukspgawvr22sflSPRGSAmT54MhmHw4YcfIj4+Hu7u7urXnJ2d0blzZ/zjH/8w\neSLthSlHqHBZHqIlY0pv9jbKxtK4lrJtNa/ttY/KmhRJZcgpkUEsAiRebryeW2eAeOGFFwAAQUFB\nGD9+PFxcXHi9uKMw9QgVQ5aHaM6Q0pu9jrKxNHsvZXNd/4oYzhy/Sc77QWRkZKBnz54ax2/cuAEn\nJyf1JkKkNXOMAzdkeQgVQ0pv+u7h/0Z2g4+7K9UqjGTvpWzqo+KfueaXcBrFtGrVKqSnp7c6np6e\njlWrVrU5EfbMHCNUuCwBrmLMCCN99/BpUhr+ve9PrPnsPBL3ptIy2Aay95FgKtrWvyKGM9fIN041\niJs3b6JPnz6tjvfp0wc3b97kJSH2yFzjwLk0U4R18sakEd0MLr1xuQfl3/PIaIas8aiUTbgy5/wS\nzhsGVVdXtzpWVVUFpZLbkEpHZM5x4Po2w5k0optRpTdjmq9seey+pVEpm+hjzucKpwARExODzz//\nvNXxXbt2ITo6us2JsFft/MRwFrWeP9IcX+PATdVMYUjzVXOqEgwhhF/m3FWSUxPTokWL8Mwzz+DW\nrVsYNGgQAODcuXPIyMjAF1980eZE2KuSchkYPe/hc4SKKZopDFndtDlbW8WVEFthzpFvnGoQ0dHR\n2LdvH8LCwnDq1CmcOnUKYWFh+Prrr9G3b982J8La8LW3ctLZbDQotIcIJ5HAJCNU+G6m0NV8pQ3N\nkLUcc+8NTsyP6/7qbcWpBgEAERER+Pe//83LRa0Vn+OKuXQkiQQCm3iIso1lFwqaOqfZ2PLYfVtF\nc1Uch7nml3AOEPaO73HFXDqS5A1Km2mGadl8Ja2qw/+S061i7L4lZ3dby8xy2nfB8ah+k6WVtZAr\nAFdzzqTu3bs3Tp06BYlEgqioKNbF+lSuXr3Ka6Isge916+11obLm6y35erqYZYZskVSGguKaVg9h\nU5SYuT7wra20TvsuOK4AXzEkEk+UllZBoaNJ2xhaA8Tbb78NT09P9Z91BQhbZ4pxxfa0hIK2h6ap\nx+5fzyzF8f2XcSunrNVDGACvJWZDHvjWVlqnfReIqWgNEBMnTlT/edKkSWZJjKWYam9lW19CQfXQ\nzMgvh7xOCVcXIboF+bR6aJpiFVd9D2Evd2feSsyGPvCtrbTelu+vIU1k1tKcRsyH+iBguuYgW16o\nLC27FNsOX0W1rEF9TF6nRFp2GXILK/HC471Nlv4iqQxf/3RH50O4vEr3yrWGlJgNeeBbW2k9LbsU\n35zO0Pu+lt9fQ2tM1tScRjRZZDXXnj17cm5WSktL4y1BlmDK5iBrWELBmJLfvp9uawSH5qpkDdj3\n822smTWQz2Q21Vjulevd9EjXCCpAs8Ss6/4NfeCbqrZpDEP2AGn+/TWkxmRtzWmkiUVXc12/fr06\nQJSVlWHr1q0YPnw4+vfvDwC4dOkSzpw5gwULFvCSEEszdXOQJTbTMfYLVCiVIbeo9dIqzeUVVhtd\nSmZ7YBuz4ZEuYlcRpFV1SNybqvP+DX3gW9PgA657gLT8/hpSY7K25jTSyFyBW2uAeOyxx9R/fvnl\nl7Fw4ULMmDFDfWzatGn48ssvce7cOTzzzDN6L5SYmIjk5GTk5+fD3d0dI0eOxJIlS+Dr6wsAOHz4\nML7++mukp6dDKBSiT58+WLp0KSIizLOPli03B7Fpyxfo0s1CMHpK6EoGuHNXalCA0BWwDN3wSN88\nDC83Z+z/+TbKq+vVx9ju39AHvrUMPuC6B0j3Tt6Y+Pc6XFw/p6oxMYBVNaeRJuYK3Jz6IE6fPo3F\nixe3Oj5ixAhs3LiR04VEIhESExPRo0cPVFZW4rXXXsPy5cuxfft2AI2LAS5cuBAxMTFwcnLC1q1b\nMXv2bJw8eRJubvy2q2ljDc1BfDHmC6R6gN/O47isBsPeBMm1hqB6YN8rrkJNLXtzljbB7T1RWVOv\n9R4Ly2u1frb5/RvzwLeGwQdcF1FsHhy4fk5VY2KUsJrmNNLEnP1gnAKEp6cnzpw5g5AQzS/+mTNn\n1ENh9Xn11VfVf5ZIJJg+fbpG0Jk2bZrG++fNm4f//Oc/yMjIQK9evThdQyAQQMh5fVrtAv3dEejv\nrv+NPBMKBRr/N1ZhmQxZBfq/QKWVteov0PVMw5p4hAIgIsQXomaLEV7PLMXRs1nIbFYD6xrkjYSh\nofguRXvAal7K50ogAMY8EIzLGaXq6xmi+f0/NixU5wP/saGhGvfZu5s/np/QS+u9RobyX9ts+d3o\n4O8OsatI532LXUXoIHHXSLshn2MYGHUNc+Drt2KLSiu4BfnSyto2P8c4BYhZs2Zh3bp1uHz5MmJi\nYgAAly9fRlJSEmvNgouUlBSdzUcpKSkQi8Xo0qUL53P6+3vYxXwNX18PFJRUo6C0BoESdwT6exj0\n+ZwSmd4HpkyuwNXscgz1aTz/8f2XDWri6drRBxHdAtR/v3y7CDu+S0NJs5K7TK7A9awy3CuphszA\nGoI+2QVVqJI14JWn+qODxB3rPj+PjHvct12VyRWQKwCJxBNDJZ7w9BLjwE+3cDtXipraBri7OSEk\n0AuD+nREWIg/JBLNf4NhEk8Mi+2CgpJqFJbWoL0R/07G8PVtvIZE4onwLn64fLtY63vDu/hp/BsZ\n8zljrmFOqvxwJD0YAcSuTpDJtf+m3N2c0J3le2soTgHiueeeQ1BQEL744gskJycDAMLCwrBhwwY8\n+uijBl/0xIkT2L9/P7766ivW1zMzM7Fy5UosW7aMcw0FAEpKqnmpQViKUChAdlEN9hxPa1PJ1E2o\nv+QHAJ8nXcO+H2+gU4AHcgoqOadTAOCBngEoLa1SH9tzXDM4NCetrON8bkOUlNdiz/E0zBoXifwS\n3Z3qLYldRXAVQX0Pnf3FePXJviiSyvBHWiFSrhUgPU+KtKwyfP3DDa3/Bi4CINhfDIDRyA++CYUC\n+Pp6QCqthvLvzpexcZ1xJ0/KOtrMU+yEsXGdWdM0Nq4zcgoqtdaYmn/OkPeaE1t+OAoXAdA1yAvX\ns3Q0iwZ6wUXA/TspkbA/ZznPgxg7dizGjh3L9e1aHTt2DKtXr8b27dsRFRXV6vU7d+5g1qxZeO65\n5/DUU08ZdG6GYaAwrKXBqlzPLNVaCs8v4T4ywd/bDaGB3JbolskVuJPHveQNAAyAy+klGP1AY+2u\nUCozqPTOxtVJCFdXJ1RUGxZMbmSX4ZdLeQY3MXVq5wGJl1urpQnOp93HwV8zNI4b829gKkolo06b\nQslACPYaswACKJq9t7nwzn46B2SEd/ZTf86Q91qCUss92rvxg0OQX6K9WXT84BBe8oVzgKirq0Ny\ncjKysrIwdepUeHt7IycnB97e3uqRSPocPHgQ69evx/bt2xEbG9vq9WvXrmHOnDl48cUXNUZMOYqj\nZ7O0lsINHZmgqyOVD803BPojrdDgXedaEQBuLiJU1kA9gkoA6N1PQ8kAv/55D84iAeoN+EHk3K9E\n4t5UjSGvadmlONQiODRXVinHvp/vYM2sONbXzT3TOOlsNipl7P03lbJ6nd8XQwZk2NPgDXthVau5\n5uXlYdasWSgpKUFtbS3Gjh0Lb29v7NmzB9XV1Xj77bf1nmPXrl3YunUrduzYwboL3cWLFzF//nws\nWbIEU6ZMMfxObBzfIxPYvkB8kskV2PLNXyiW6u/v4EJer0Rhmeb+BVwf99V/9xnUK7j3c9Q1MK2G\nvB46laFz/w4AyLlfhZRr+RgcFaQ+ZomZxnx9XwyZn2OJuTxEO1Xgvn1XivwyOYL8XNGjE7fCOlec\nAsS7776LmJgYrF27FnFxTaWnUaNGYeXKlZwutHbtWjg5OWHmzJkax1NTUwEAH3zwASorK/Hee+/h\nvffeU7/+ySefYMCAAZyuYcuKy7h1LBsypLB5ye/7lCz8ejmfh5Q2yb1v/rZnbRQNSniJnVCpZfa3\nNqqamb+PmPP9HD+fqw4QlpppbOyMblpPyX5YdCZ1c5cuXcLu3bvh7Oyscbxjx464f/8+pwvdvHlT\n5+tffvklp/PYq3Z+Yk5DCo2ZoRvgK0aenpnRKm4uIiiVStQ12Fa7rrxBicdGdEXS2WyD51Rk5Vfg\nTp4UdQ26l/dQKSyrUZfMLTXT2NAJfi0fJq7OQnTwc8ejA7tgcFQg7+kjpmWuggmnMT8NDew/uKKi\nIojFVArhg2rCli7GztAtlMpwt5hbgKitU0Ds6oQH+wXB28PF4Gs1JxQ0zlcwB1dnIWLD22PBxN4G\np1smV0Dwdx8IF/K6xo2eDGnm4Zsh3xfVwyQtu0xdAJHXK5FTWIVPjl7Hmp3nkJZdynsaielwKZjw\ngVOAiIuLw/79+zWO1dXV4T//+Q+GDh3KS0IIkDA0FP4+7LPG2zJDl+usW5Xy6noUSmsxL6EXIkP9\nIHZtfHAKBdAyZqY1sasISgZ6l+zgSweJu3ov7pbp1qfxfQLO9+bqLEQ7H8MW7jMFrvsS61vGJKew\n+u8AQkHCFpizYMKpiWnp0qWYNm0arly5gvr6erz11ltIT09HfX09vv766zYngjSKDJXglaf6t5oH\n0daRCVyaI1rKyq9AOx8xlk6NQcq1Anx98rbWETMtCQXgvVNcn0fjmiZUthx1c+hUBtLvav9BBfi6\n4X/J6ZBxzB9VMGIAXhbu09cvUCSVoaRChh6MAC7NohiXkSxc12zi0hxG/RfWwZwrCnMKEF27dsWR\nI0ewd+9eeHt7Q6lUIiEhATNmzIC/v3+bEkA09e0RgM7+YhSU1PA2pJDLekMtNf+CnbmSzzk4WEKX\nDp6s7eiqUTexEZXIyq+EgmVCVWMJXGDQcGBVMGrrwn36Ohlbvu7u5oTQQC+Mb1ZY0DcE1ZDao7ZR\nT7QfhH7mDJ7mXFFYb4Coq6vD9u3b8eSTT2LhwoVtvqA1ssaSEd9DCuOHhOBucTXniWiqLxjXEqiK\np9gJVRxGErmIBKjjYSKPn5crpozqrvX14+ezcfCXdLBdSiQQYHBUB/x86S7n67UMRvFDQpBXWMUa\nQL3EzlqbBfV1Mj7yQDB+vJCn8XpNbYPWCXvavi+G1B7ZSp20HwQ71TOjvKYOZ67kmzV4mnNFYb0B\nwsXFBZ9//jn+7//+r80XszaOVDKKDJHg0bjOOPBLOqf3q75g1zNLOT1cXJwECAv2xbA+gfjyxC2d\nn3F1FoLhoXNCAMDL3Vnr62nZpfhfcrrWZcEVDIM/bhRxLmFrC0ZKLTM2GB0zOfR2MuoYjWXI6ChD\nao9spU7aD0JTy2dGS+YKnuZaUZhTJ3VsbKx6voK9YBvZofrHtdcOu9iI9pxG6ni4idRfMFUJVBdX\nJyFeebIflk6NweCoIL2jazr4ufMyjJZB48S1HUlpSLmWj7NX83H2r3x159yhXzOg1DNytZBjR15Y\nJ2/WH3zS2WydO++1HE1SJJXh7NV8pN8r13k9fUN1DemE1NWZ3VzLUieX2uPN7DKkXCvglA5bx/bM\n0IbPkURsVP1PzQdjiF1FiAz14zUwceqDSEhIwL///W/cvXsXffr0abU/g2qXOVviiCUj7qVJAbLy\nK9HOR8zpM92CfRDRxU/9d32lm9EDu+DL4zf0bivKVVmlHJ8cbdr2VihoXLK9oKSGl/MLBcDzE6La\ntF1pcblMZ8nTUIZ0QqoeJvt+voMcLZMB2UqdXPovlAzw9cnb8PV0sbvfS0uGbmpl6s2UVP1PpZW1\nkCsAV3PuSd3ca6+9BgDYtGlTq9cEAoHN7UltbRvPmxOXNZqqaxtwIDkdSSlZCA30RnSYxKDqLJfR\nNb9dyTeo09wQSga4V8xPcFCdj+1hzHU0ycVbha36E9rK0E7IyBAJ1syKQ8q1fBw/n4vCshrI65Q6\nR8lx7b/Qt+6TPTC0Lw4w32ZKAb5iSCSeKC2t4n3hQk4B4qeffuL1opZmTRvPm1tkiAT/N7IbPk1K\n07llJ9C60/SvjFL1A7/5TFy2B4O+0TW6OnetjbaHMdfRJBdvFhkcHPRtqWpsJ+TgqCAMjgritPCe\nIf0X9lqgUjF0LhFgvr3JTYlTgAgICEBDQwPc3c2/y5opWNPG85bg4+6qNzg0V1Ypx18ZpX/PiWgq\ngeYUVuGrH27izJV8rR372kbXRIZIMP/xKGw79BeqzTxnwlDaHsZcHqAd23ngLsdlTppTMo2z0Nn6\n8vnohOQ6Si5+SAhyCyv1jkyz1wKVijFzicyxN7mp6eyklkqlmD9/PmJiYhAbG4upU6ciNzfXXGkz\nGVMua2ELuHQ8t3QzuwwHk9Pxv+QM5N6vgryusf+grR37tTz1Q5iKvoexvtnM/cMDjF4KnWEadwZT\ndUK6uzmhF8+dkPpEhkjw1MM9oG9nT3suUAHcnhnNmWtvclPTWYPYtGkTrly5goULF8LV1RV79uzB\n6tWrsXPnTnOlz2SsYeN5SzFm4pySAY6fy4FCy/BUYzr2D53KYJ28Zg0a99z20zuDXV9/i7+PGEd/\ny2pDkGDw8hPRgADoHuIPFwG/G+RwmQM0OCoIZ64UcBp3b41zivjCpf/OFHsyWJLOAHH69Gm88847\nGDVqFABg+PDhSEhIQH19fauVXW2NuTbcsFbGbCikLTioGNIOXSiVWXS5cCchIHISqmtCzbm5CDHj\n0QiNPR900dffYmgwbk4mV0DJMOjdtXF/Yb629zR0DpC+AlV0NwkS96ba9ZwiXc+MYX0C4evpaneb\nKekMEPfv39fYFrR79+5wdnZGUVEROnbsaPLEmZoj75Rlig2FDGmHLi6TcVpeWyQEHuzXETdypCiR\n1kLeoITL37vHtaUc3aAEGliCAwA4ixqbdK5nlhpUEtbWrh8/JAQ5hZVa50voYoqmG2NmR+t6OEZ3\nk+CHFqO07HW2taM9M3QGCIVC0aqmIBQKobDljZ9ZOOpOWc2/7BdvFeLob1ltChSGPMy4dvr16OKH\nmWMjoVAwGj/Kz4/d0Fkqd3YSwM3ZyahRUpWyevUoLz5KwpEhEvh7u6FaZnjpn0tfmKHNOsbOAdL2\ncEzcm+pwc4oc5ZmhdxTTokWLNIJEXV0dli1bpjFZzh76JPhmS22xAb5ijIkLgY+HC6fhr9oY0rHf\n3leMTgEeOldZdRIJMGNMpEY6VefX1eTh4+GM5xMaa77G1pBUecBHSbhQKmu1nSoX+vrCjFkqho85\nQM3/HRxhTpEt/Zb5pjNATJw4sdWxhIQEkyXGHtjy+k5cOiOdRALWfZsN6dhPyy7FoVMZyNbxYHES\nCTB5ZBiiewSwtrtz7UOKDJHgRk4ZPth/mfOOcWzaUhLmOobexUmAugaGU1+YsYvo8T0HyJ7nFNny\nb5kvOgPEunXrzJUOu2DNK19yLQXpXSbjgWBcaTZhjsvDrPm1L94qxKFfM1iDDNAYGEIDvTBxRDf0\n7qZ7KXmu7cFKBdOm4KBibEmY67ybl5+IhpJhOLVrG9tMxPccIHudU2TNv2Vz4jRRjnCj70f7zakM\nMMNg1qqqoaUgLiXzR+NCOHXSse2DrG/9pZBAL8ydEIWiMhmKpDJIJJ5671Ffe7Axk5zYGFsS5ro8\nc/P1rADNwBro3zRJtS3NOnwvFW3OpafNyRHXamNDAYInXH60d+5W4N/7/jRbVdXYUpC+kjmX2gjb\ntbkszpd5rwKrPj0HeX3jOkHhXfwwNq4zwjv76f2sNu19xWjvJ9a6UB1XbSkJGzLvhi2odw3yxrQx\nkQj2N2yrU22jqvicA2Rvc4ocoV+FK9GaNWvWWDoRfKmp4bYZjilk51fi1JV8Tu9tUDAoLq9FWnYZ\nunTwVH/JhEIBxGIXyGR1vOzl/PmxG8gtZH8o1tYpUFYlx9De2sf6e7g5I8BXDA+3xkEKadml+PzY\nDRw+k4FTl/Px21/5uJ5VBom3a6sfiq5r68IA6slzDQoG90trcC1LM5+KpDJk51cCAqjTpktadilO\nX77X5mamHp198ciAzkZ9NsBXjC4dPFFWJUe1rB4Nisa+hh6dfTH1H93VgVoVWHMLq9TNcA0KBkXS\nWly+XYTOAZ7w/3uXP23NdEBjMBs3KJQ1f7imhe974xPfv5XmuPyWGxQMYnq0s4oAwUdeeHiwrwZA\nNQieGNOMYcqqKt+lIENqI8asfKlL87X1jek0TDqbrXMtIVXnsC6GloTZallc+kx0NW2UlNfi6Nks\nLJka0+ZmHb7H89vT/AB77VcxBgUInhizfAVguqoq36NLDGmTNWblS33S86T4+EgVyqub5jVwaS7j\nEqy4bF70fyPDOAVyLn0+LftMVMFEKBLoTWvm398Xvpp1+B7Pbw/zA+y1X8UYFCB4FD8kBPeKNR9i\n+phqCCCXUpCLk4BTKcjQ2ghfncLN1TUwqGtgz1dVgGrnI25Var+TK+UlHb6eLnrfY0gtq0gqwx83\nCnHpdhHuFVdDJlfAxVmIOj39NKrvi6MvFWNq9tavYiwKEDyKDJFg9ANdcCCZ277PgOmqqlxKQQql\n5kY42jqfDa2NGFubaoub2WVYtfOcehOcAB83QCDA/VK+dpXTs5wpuNWyVO9LvyttVXPRFxwAze+L\nPTXrWBsKwI0oQPAstmd7HD3LffVOU1ZV44eE4FaeVOvqnwolg63fXEX8kBD8lV6qtVlEKBLA+e/1\nj7RpGei4LgYoANCtkzdk8oY27QKnZKCxBHlOoeF7MOg+v+5mKC61rIy8cvz3yHVUVBs/mKIry/fF\nHpp1rBEFYAoQvDOk9KyqqqpK7oHt3DmN++fK30cMkUAAhY5l7WpqG3Dg53SNd6iaRXIKK+Hv7YYi\nqUxncABaBzquO9c5OQkBBiiR1mp9j7eHC2rlDbxMdmM7d01tvc4RQa5OQr21PC61LHmDEvIG44OD\nv48bEoaGGv15YhxHDsAUIExAX+nZ1UmIbsE+6NNN0qpDk49x/ypcV0zV9misljVwWmBOW5ssl53r\n6huUSL/HXvJ2cRIgsqs/xsZ1xrdnsnhtsnJ1EaJbRx/EDw7Bvp/v6Jwj0cHfXecDIi27FN+czuAt\nbSrNl95oPg/C2P0gHHlNIWIcChAmoK39smM7D8RGBCA2vD2Ky2WsHZqXbxcjp6CSl6n8pugsbk5f\nm2xbrx8S6I135g9FaWkViivkvAaIZ0b3xODegY1/acM4eraOaT60XHoj0N9dvTG9MWl09DWFiHEo\nQJiIvvbLz4/dMPlUflN2Frs6CfHyE9Gtlofg8/p5RVUoKKmGiwDwddc/iogrsasI3YN9APy90qpU\n90qrRVKZ1qHIujqm24Jt6Q1j0JpC9q9IKkNOiQxiESDxctP/AQNQgDAxtvZLc07lN2boLRfyBqXe\njtu2Xl8mV6CwtAbB/vwOnW3eX9KW+SJ8TwhU4XMYJa0pZL/MUTMU8nIWYhBDHkptFRkiwfMJUXB3\n47cswHV4rmror7HXaC9pXKSuva8Yndp5GHWe5lo+fFWBR1862O7V0AmBrk5CeHtorwm5OgkRGerH\nW6nekIIIsS2qmmFadpl6rxNVzbDxeCkv16EAYQFteSgZIzJEggUTe2t9OHEY4t+KIcNzY3u213u/\nbLoGeSPQvyko9I8I4PQ5FycBunTwQJcOnhC7Nl5X7CpiffiqmsF00XavXP4dm+sW7IN5Cb0QGeqn\nka6wTt54clQY3pozEEunxvBW+jNnQYSYF9c5N21FTUwWYImp/JEhEsxL6MU68adPNwn+arHHQ4Cv\nGGUVctYtOw1tAjGmL8LPy7XVkM7YiPb49nSmzpFZrk5C/PPJvur2ey5j2I2dNWvMkGZzjq2nNYXs\nkzmbqClAWIgpp/JrG86o6+E0hmWPh7TsUt5mkuq6XyeRAEIBWu+mFqp5jfa+YoR18tH5QO4W7KPR\nuctlDHtbZs1yHdLc8jzmGFtPawrZJ3Pu4kcBwoR0jTvX9lBqyzwIrp1W2h5OLY/zWdrV9xBu5yPm\ndA1TBVZj75XLkGZLPoBpTSH7Y86aoYBh+F5N3XKKiiotnQQAho8uUD2UOkjcEdGtcQ9mQydD6RqP\n7+flalXDGbk+hEUigXrsf/P8MLZmY+qJYqZsNtKWF1zwWRO0Fm3JD3uQuDdVZ80wMtQPS6fGcD5f\nQIAX63GqQfDMmHHnqpK7SGREb/HfbGk4I1sNxpCHt6GlfXNNFLPWJRloTSH7Y66aIQUInlniQW3L\nWyTqenj37uav87NcHsg0UayJtQYwYjhzrTZLAYJHlnpQc+20+uNmIQZEWKZNnK2GoO/h/fyEXhim\nZ/FCfTUPW6pZEWIIVc2wtLIWcgXgasszqRMTE5GcnIz8/Hy4u7tj5MiRWLJkCXx9fdXvOXz4MLZs\n2YKioiKEh4dj9erV6N27t7mS2GbmHF3QHNdZxgd+SUfS2SyzrsOjq4Zw6FSGzof30bNZGBbLPsmO\nS7ORLdesiOnY26KFAb5ik/XHmC1AiEQiJCYmokePHqisrMRrr72G5cuXY/v27QCAP/74A2vWrMGW\nLVsQFxeHL774As8//6Mv8nQAAA95SURBVDx++OEHeHrytwS2KVlq3Lkh4/HN2byiq4ZwM7cMSj0L\nzWbmV6jXYuJ63nvFVRj9QBcM6NneYgGbWCdatNBwZgsQr776qvrPEokE06dPx+LFi9XHDhw4gEce\neQTDhg0DAMyZMwe7d+/Gjz/+iIkTJ3K6hkAggNCCc8OD/N3RraM3rmdpf1A3zg52Z31NKBRo/N8Q\njw0L5bRBj0pZpRzfpWTrbedvi+9StDfv6AsOQNNaTF0CNPNL13nLq+txIDkdSSlZ6NTOAy5OQp0T\n68SuInSQuLdpgIA5tOW7YY8MzY/rmfqbM3t1tc0gYcrvhsX6IFJSUhAREaH++40bNzQCgUAgQGRk\nJG7cuMH5nP7+HhAYs24Ej6aNicTGvZdQUt56Axx/HzdMGxOpd1MgX1/D1xwaKvGEp5cYB366hdu5\nUtTUNuj9TFZBJeoYgcZyFnwpKKlGZn7bhh27uzmhvcRdIz+4nlcmV+DO3Qo46Xnwh3fxQ0Q3bkt4\nWANjvhv2jGt+HN9/WWdz5vELuVqbM22FKb4bFgkQJ06cwP79+/HVV1+pj1VXV8PLS3Msrre3N6qq\nuK9/X1JSbdEaBAAE+4sxZ3wkjp7NQmaz0QVdg7yRMDQUwf5irWv6C4UC+Pp6QCqthlLfTjssOvuL\n8eqTfVEkleFC2n3s+1n33tg1tQ24k10CFwH/48hvZ5VAJtcfpHTpGuSFQH/N/DD0vA0KBk4iAeuO\ncX5erhgb19moPRbMra3fDXtjSH4UlslwK0d38+utnDLczCiyyaZGPr4b2gqtZg8Qx44dw+rVq7F9\n+3ZERUWpj3t4eKCyUrNkWFFRgS5duEd1hmGgMM3eOAaJ6OKHiC5+rOPOuXQiKZVMmzqbJF5uiAlv\nj2/P6N4bW+wqgsTLzSQTjSTebVue28/LFROGhALQzA9jzisUAN07eeNucXWr4YDhnf3U57aFzsu2\nfjfsDZf8uF9So17xVBuZXIH7pTW8jwIyJ1N8N8waIA4ePIj169dj+/btiI2N1XitZ8+euH79uvrv\nDMPgxo0bGD16tDmTyCtLjju39Do8bdksqHsnb0wc0a3VWkzGnreugcHEEd20LudBnZf2jRYtNJ7Z\nGmR27dqF999/Hzt27GgVHABg8uTJ+PHHH5GSkoK6ujrs3LkTcrkcjzzyiLmSaHfih4TAz8uV9TVz\nrMOj6/rahHXyxooZA/QukGfIeVU//gBfMSJDJK2CgznW1SeW05Yl3R2d2WoQa9euhZOTE2bOnKlx\nPDU1FQAwYMAArF69GitXrlTPg/j4449tZoirNTLXbEtDru/iJICSgdY+gUkjuhl1Xl10/fjNMZHO\nFpqu7B0tWmgcWqzPiphyATJLr8PT/PrF5TJOQUuVHzczilBQXAORSACFgtF40BZJZbh4qxDHz+Wi\norqu1XV1LVRYKJVhzc7zepse1syKMyrP+Gy6cvTF6VoyJj/scdFCgJ/vBi3WZwK2VDK09Do8za+v\naurRF7SuZ5bi+P7LuJFZCnmzuQwuTgKEdfJVP2jHxIUgpIOXwT9+U06kozWgrA8tWmg4ChBGoE5N\n3bgGTl1BS9fy5XUNTKsHrbYff5FUhuuZpaxp4bPzsuU90xpQ1svShSVbQgHCQFQy1I7PwKnrAavC\n9qBV/fjTskvx+bEbOtPCx0gvtnvu1M4D2fd1N3fSGlDEFlh4WpntMddm4baGz9FAXBbZU1E9aI1N\nS1tGemm7zp27Fahv0N0WrGq6IsSaUYAwgCGrgzoaPgMnl74BFbYHrSFpUY2Iigz1g9hVBKCxWSky\n1E9vbZBLLUcbGndPbAE1MRmAVgdlx/ey2lyXLwdaP2iNSYsxnZeG1HLY0Lh7YguoBmEA1YNLF0cs\nGRoSOLngMrFJpeWDti1pYZtIp40htZyWaNw9sRUUIAxAMzLZmSJwcpktzfagNVcQ53IdVychwjp5\nG9x0RYi1oCYmA9GMzNZMse5TZIgEz0/oheMXctnnQQT7ss5xMNcaVFyu0y3YB0unxtC4e2KzKEAY\nyNLLV1grUwTOXl0lGBbbBTczinC/tAZCgQBKhtH7oDVXEOd6HRp3T2wVLbXRluvxXDK09eUU+F7K\noC35Ya5lFcx1HVv/bvCN8qMJLbVhpahkqMmaljIwV1qs6Z4J4RsFCMI7awqc5kqLNd0zIXyhUUyE\nEEJYUYAghBDCigIEIYQQVhQgCCGEsLKrYa6EEEL4QzUIQgghrChAEEIIYUUBghBCCCsKEIQQQlhR\ngCCEEMKKAgQhhBBWFCAIIYSwogBBCCGEFQUIQgghrChAEEIIYUUBwgK+++47PP300+jfvz969erV\n6vVTp05h/PjxiI6ORnx8PM6cOWOBVJpHYmIixo8fj/79+2PYsGFYuXIlpFKpxnsOHz6Mhx9+GH37\n9sXkyZNx9epVC6XWPDZt2oRRo0ahf//+GDx4MF5++WXcu3dP/bqj5QcAKJVKTJ06FRERESgoKFAf\nd6S8eP311xEVFYWYmBj1f7t379Z4D+/5wRCzO3XqFHP06FHmwIEDTGRkpMZrOTk5THR0NHP48GFG\nLpcz3377LdO3b18mNzfXQqk1rQ0bNjDXrl1j6urqmJKSEmb27NnM/Pnz1a9fuHCB6du3L3P69GlG\nLpczH3/8MTN48GCmsrLSgqk2rTt37jAVFRUMwzBMTU0N8+677zJTpkxhGMYx84NhGObTTz9lZs6c\nyYSHhzP5+fkMwzheXixbtoxZsWKF1tdNkR9Ug7CA4cOHIz4+Hp07d2712jfffIOoqCg89thjcHFx\nQUJCAnr16oXDhw9bIKWm9+qrr6JXr15wdnaGRCLB9OnTcf78efXrBw4cwCOPPIJhw4bBxcUFc+bM\ngYuLC3788UcLptq0wsLC4OXVuEcwwzAQCoXIzMwE4Jj5kZmZiT179mDZsmUaxx0xL3QxRX5QgLAy\nN27cQFRUlMaxXr164caNGxZKkXmlpKQgIiJC/feW+SEQCBAZGWn3+XH06FHExsYiJiYGu3btwksv\nvQTA8fJDqVRixYoVeO2119RBU8XR8gIAfvjhB8TFxeHRRx/F+vXrUV1drX7NFPlBAcLKVFdXt/oh\neHt7o6qqykIpMp8TJ05g//79+Ne//qU+5qj5MWHCBFy8eBFnzpzBSy+9hPDwcACOlx+7du1CQEAA\nRo8e3eo1R8uL6dOn49ixY/j999+xZcsWXLhwAW+88Yb6dVPkBwUIK+Ph4YHKykqNYxUVFfD09LRQ\niszj2LFjeOONN7B9+3aNUpCj5odKQEAAnnzyScyfPx9SqdSh8iM7Oxs7d+7UeAg250h5AQC9e/dG\nu3btIBQK0aNHDyxfvhwnTpxAXV0dANPkBwUIK9OzZ09cv35d41haWhp69uxpoRSZ3sGDB7F69Wps\n374dgwYN0nitZX4wDIMbN27YdX601NDQgJqaGhQWFjpUfly8eBGlpaWIj4/HwIEDMWnSJABAQkIC\ndu/e7VB5wUYobHx8M3/v+WaS/DC6e5sYraGhgamtrWVOnz7NREZGMrW1tUxtbS2jVCqZ7OxsJjo6\nmjl69ChTV1fHHD161K5HMX3xxRdMXFwcc/nyZdbXL1y4wPTr1485e/YsI5fLmR07dtj1SBWFQsF8\n+eWXTHFxMcMwDJOfn8+8+OKLzEMPPcTU19c7VH7U1NQw+fn56v9SU1OZ8PBw5sqVK0xVVZVD5QXD\nMExSUhJTXl7OMAzDZGZmMlOmTGFeeukl9eumyA/actQCDh06hOXLl7c6/tNPPyE4OBinTp3C+vXr\nkZubi86dO2P58uUYNmyYBVJqehEREXBycoKLi4vG8dTUVPWfDx8+jI8++ghFRUUIDw/HmjVr0Lt3\nb3Mn1SyUSiXmzZuHq1evQiaTwcvLC3FxcVi0aBG6dOkCwLHyo7m8vDz84x//wK+//orAwEAAjpUX\nM2bMwM2bN1FXVweJRIJHHnkECxcu1GhC4js/KEAQQghhRX0QhBBCWFGAIIQQwooCBCGEEFYUIAgh\nhLCiAEEIIYQVBQhCCCGsKEAQwpO8vDxERETgjz/+sHRSCOEFzYMghMXrr7+Ob775BgAgEonQoUMH\nDB8+HK+88gr8/PxYP6NQKFBaWgpfX184OzubM7mEmISTpRNAiLUaMGAAPvjgAygUCly9ehVvvPEG\nCgoK8PHHH7d6r1wuh6urKwICAiyQUkJMg5qYCNHC2dkZAQEBCAwMxMMPP4xnnnkGp0+fRnp6OiIi\nIvDtt99i9uzZ6Nu3L7Zt28baxFRcXIxly5Zh8ODB6NOnD8aNG4fvv/9e/XpmZiZeeOEFxMbGYuDA\ngXjhhReQm5urfj0/Px8LFizAwIEDER0djYcffhifffaZWfOBOC6qQRDCkZubG5RKJRoaGgAAGzZs\nwJIlS7BmzRoIhUK0bK2VyWSYNm0aPDw8sHHjRgQHByMrKwtyuRwAUFRUhKeffhrjx4/H3r17IRQK\n8Z///AezZs1CUlIS3Nzc8Oabb6KmpgY7d+6Ej48P8vLyUFJSYvZ7J46JAgQhHNy5cwe7d+9GdHQ0\nPDw8AABTp05FQkKC+j15eXkan0lKSkJ+fj5+/PFHdOjQAQA0tpndu3cvQkJCsHLlSvWxdevWIS4u\nDsnJyRgzZgzu3buH0aNHq/fICA4ONtk9EtISBQhCtDh//jxiYmKgUChQV1eHgQMH4q233lK/Hh0d\nrfPz165dQ/fu3dXBoaWrV6/ir7/+QkxMjMZxmUyG7OxsAMDMmTOxevVqnD59GgMHDsSIESMwYMCA\nNt4ZIdxQgCBEi+joaKxfvx4ikQjt27dXL0muqim4ubm16fxKpRKDBg3CqlWrWr3m4+MDAHjiiScw\nfPhwnDlzBufPn8ecOXPU+xETYmrUSU2IFm5ubggJCUFwcHCr/Sq4iIqKwp07d1BYWKj19fT0dAQG\nBiIkJETjP19fX/X72rdvj0mTJuG9997D2rVrcfjwYbvdd5lYFwoQhJjI+PHjERgYiAULFuD3339H\nbm4uzpw5g5MnTwJo3ACmoaEBL730Ei5duoTc3FycP38e69b9f/t2iKIhFAVQ+Bg1mAQtrsHomgRx\nFeKAwQ0YDa7B6DosYnEHYpz2p1d/Jsz5FnDhpQP38n44zxOAvu/Z953rujiOg23bKIricweRvskV\nk/QlSZKwLAvjONJ1He/7UpYlbdsCkGUZ67oyTRNN0/A8D3meU9c1aZp+5gzDwH3fxHFMVVXM80wU\nRX/1LP0j/qSWJAW5YpIkBRkISVKQgZAkBRkISVKQgZAkBRkISVKQgZAkBRkISVLQL9egS5BluPbi\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff600bd7fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.linear_model as lm\n",
    "\n",
    "linear_clf = lm.LinearRegression()\n",
    "\n",
    "# Fit your classifier\n",
    "linear_clf.fit(X_train, Y_train)\n",
    "\n",
    "# Predict points from our test set\n",
    "Y_pred = linear_clf.predict(X_test)\n",
    "\n",
    "# Plot predicted vs true prices\n",
    "plt.scatter(Y_test, Y_pred)\n",
    "plt.xlabel(\"Prices\")\n",
    "plt.ylabel(\"Predicted prices\")\n",
    "plt.title(\"Prices vs Predicted prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "As shown from the scatter plot, our model is not perfect. Ideally, we would see a line of slope 1 from the points if our model was 100% accurate.\n",
    "\n",
    "Now let's also compute our mean squared error. Fill out the function below and compute the MSE for our predictions on both the training data `X_train` and the test set `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478    10.23300\n",
       "26      0.67191\n",
       "7       0.14455\n",
       "492     0.11132\n",
       "108     0.12802\n",
       "37      0.08014\n",
       "157     1.22358\n",
       "472     3.56868\n",
       "118     0.13058\n",
       "114     0.14231\n",
       "175     0.06664\n",
       "192     0.08664\n",
       "272     0.11460\n",
       "144     2.77974\n",
       "373    11.10810\n",
       "383     7.99248\n",
       "356     8.98296\n",
       "277     0.06127\n",
       "220     0.35809\n",
       "450     6.71772\n",
       "141     1.62864\n",
       "369     5.66998\n",
       "67      0.05789\n",
       "361     3.83684\n",
       "168     2.30040\n",
       "499     0.17783\n",
       "394    13.35980\n",
       "400    25.04610\n",
       "193     0.02187\n",
       "249     0.19073\n",
       "         ...   \n",
       "276     0.10469\n",
       "443     9.96654\n",
       "191     0.06911\n",
       "385    16.81180\n",
       "293     0.08265\n",
       "413    28.65580\n",
       "343     0.02543\n",
       "257     0.61154\n",
       "308     0.49298\n",
       "149     2.73397\n",
       "130     0.34006\n",
       "151     1.49632\n",
       "359     4.26131\n",
       "99      0.06860\n",
       "372     8.26725\n",
       "87      0.07151\n",
       "458     7.75223\n",
       "330     0.04544\n",
       "214     0.28955\n",
       "466     3.77498\n",
       "121     0.07165\n",
       "505     0.04741\n",
       "20      1.25179\n",
       "188     0.12579\n",
       "71      0.15876\n",
       "106     0.17120\n",
       "270     0.29916\n",
       "348     0.01501\n",
       "435    11.16040\n",
       "102     0.22876\n",
       "Name: CRIM, Length: 339, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"CRIM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[  1.02330000e+01   6.71910000e-01   1.44550000e-01   1.11320000e-01\n   1.28020000e-01   8.01400000e-02   1.22358000e+00   3.56868000e+00\n   1.30580000e-01   1.42310000e-01   6.66400000e-02   8.66400000e-02\n   1.14600000e-01   2.77974000e+00   1.11081000e+01   7.99248000e+00\n   8.98296000e+00   6.12700000e-02   3.58090000e-01   6.71772000e+00\n   1.62864000e+00   5.66998000e+00   5.78900000e-02   3.83684000e+00\n   2.30040000e+00   1.77830000e-01   1.33598000e+01   2.50461000e+01\n   2.18700000e-02   1.90730000e-01   2.63630000e-01   1.10874000e+01\n   2.37934000e+00   4.20300000e-02   1.12658000e+00   6.23560000e-01\n   5.51500000e-02   3.55100000e-02   1.64390000e-01   2.92400000e+00\n   1.51902000e+00   3.15000000e-02   4.62960000e-01   7.89600000e-02\n   7.90410000e-01   4.75237000e+00   3.68940000e-01   1.44760000e-01\n   9.06000000e-03   9.26600000e-02   2.81838000e+00   3.84970000e+00\n   2.48017000e+01   2.98190000e-01   5.34120000e-01   5.11830000e-01\n   2.43938000e+01   4.87141000e+00   9.74400000e-02   4.01100000e-02\n   5.44520000e-01   4.89822000e+00   1.96570000e-01   3.87100000e-02\n   2.36482000e+01   1.03280000e-01   1.00840000e-01   5.30200000e-02\n   7.85700000e-01   8.82900000e-02   3.47428000e+00   6.07600000e-02\n   1.30100000e-02   1.34284000e+00   1.65660000e+00   5.42500000e-02\n   7.67202000e+00   8.30800000e-02   4.02020000e-01   2.24890000e-01\n   2.00849000e+01   2.11610000e-01   4.46200000e-02   1.75050000e-01\n   2.45220000e-01   1.80028000e+00   6.39312000e+00   5.56100000e-02\n   5.37200000e-02   3.76800000e-02   9.82349000e+00   2.15505000e+00\n   5.87205000e+00   2.36862000e+00   7.36711000e+00   4.29700000e-02\n   1.50380000e-01   2.07460000e-01   1.15040000e-01   4.09740000e+00\n   9.25200000e-02   9.60400000e-02   1.20830000e-01   1.70900000e-02\n   9.29900000e-02   1.00080000e-01   2.17700000e-02   3.39830000e-01\n   2.37857000e+00   3.53700000e-02   4.30100000e-02   5.11358000e+01\n   9.91655000e+00   1.96500000e-02   1.69020000e-01   5.47900000e-02\n   6.14700000e-01   1.20482000e+01   1.14250000e-01   8.81250000e-01\n   8.79212000e+00   7.88600000e-02   5.02300000e-02   8.89762000e+01\n   5.82401000e+00   5.20177000e+00   1.41030000e-01   8.19900000e-02\n   6.53876000e+00   1.36781000e+01   1.23290000e-01   5.78000000e-02\n   2.63548000e+00   2.49800000e-02   5.08300000e-02   4.83567000e+00\n   8.20058000e+00   3.31470000e-01   3.69200000e-01   2.24236000e+00\n   3.22640000e-01   4.66600000e-02   6.63510000e-01   5.75290000e-01\n   1.71340000e-01   6.89900000e-02   7.24400000e-02   3.15330000e-01\n   2.07162000e+01   6.15100000e-02   2.59150000e-01   1.09600000e-02\n   1.80846000e+01   1.31170000e-01   1.84982000e+01   7.52601000e+00\n   3.29820000e-01   1.35222000e+01   1.22690000e-01   1.78990000e-01\n   3.58400000e-02   1.50100000e-02   5.73500000e-02   1.02900000e-01\n   5.60200000e-02   1.58603000e+01   1.42502000e+00   9.37800000e-02\n   6.41700000e-02   7.72990000e-01   1.20742000e+00   3.32105000e+00\n   9.59571000e+00   2.89900000e-02   4.07710000e-01   1.22040000e-01\n   4.33700000e-02   1.13290000e-01   1.52880000e+01   9.18702000e+00\n   6.64200000e-02   1.27440000e-01   2.20511000e+01   5.29305000e+00\n   2.29690000e-01   6.12900000e-02   4.81900000e-02   1.08342000e+01\n   6.90500000e-02   1.53800000e-02   8.24809000e+00   1.48660000e-01\n   3.82140000e-01   1.00623000e+01   1.40520000e-01   1.22472000e+01\n   2.31390000e+00   8.18700000e-02   3.61500000e-02   1.98020000e-01\n   1.71710000e-01   2.29270000e-01   1.38799000e+00   5.78340000e-01\n   2.41030000e-01   1.77800000e-02   5.44114000e+00   9.55770000e-01\n   8.64476000e+00   5.37000000e-01   5.40110000e-01   4.59000000e-02\n   1.83377000e+00   9.33889000e+00   2.49800000e-01   1.10270000e-01\n   5.57780000e-01   3.25430000e-01   5.73116000e+00   2.11240000e-01\n   3.03470000e-01   1.30751000e+01   1.95100000e-02   4.41700000e-02\n   6.37960000e-01   2.44668000e+00   3.35900000e-02   1.78667000e+01\n   3.16360000e+00   1.19511000e+01   4.56000000e-02   2.10380000e-01\n   9.39063000e+00   1.09590000e-01   3.04100000e-02   5.20580000e-01\n   2.51990000e-01   2.17190000e-01   1.29320000e-01   6.65492000e+00\n   2.14090000e-01   2.79570000e-01   7.83932000e+00   1.00000000e-01\n   6.21100000e-02   9.06500000e-02   3.44500000e-02   1.46336000e+00\n   1.59360000e-01   7.01300000e-02   1.42362000e+01   9.06800000e-02\n   3.49400000e-01   6.56650000e-01   1.32620000e-01   4.98100000e-02\n   8.15174000e+00   2.73100000e-02   6.28807000e+00   1.50860000e-01\n   2.19770000e-01   1.18123000e+01   4.11300000e-02   1.36420000e-01\n   1.61282000e+00   8.49213000e+00   8.25260000e-01   3.76619000e+01\n   3.69695000e+00   3.93200000e-02   5.49700000e-02   1.43337000e+01\n   5.36000000e-02   3.11300000e-02   5.50070000e-01   1.06120000e-01\n   6.29760000e-01   2.53560000e-01   5.66000000e-02   2.25971000e+01\n   2.21880000e-01   2.01019000e+00   6.61700000e-02   2.39120000e-01\n   9.76170000e-01   7.50300000e-02   5.69175000e+00   4.75470000e-01\n   1.27570000e-01   1.36000000e-02   4.22239000e+00   8.87300000e-02\n   3.69311000e+00   8.44700000e-02   6.71800000e-01   8.37000000e-02\n   4.52700000e-02   5.82115000e+00   7.87500000e-02   2.44953000e+00\n   1.54450000e-01   2.53870000e-01   3.04900000e-02   3.30450000e-01\n   8.22100000e-02   8.52040000e-01   2.69380000e-01   6.80117000e+00\n   1.27346000e+00   1.04690000e-01   9.96654000e+00   6.91100000e-02\n   1.68118000e+01   8.26500000e-02   2.86558000e+01   2.54300000e-02\n   6.11540000e-01   4.92980000e-01   2.73397000e+00   3.40060000e-01\n   1.49632000e+00   4.26131000e+00   6.86000000e-02   8.26725000e+00\n   7.15100000e-02   7.75223000e+00   4.54400000e-02   2.89550000e-01\n   3.77498000e+00   7.16500000e-02   4.74100000e-02   1.25179000e+00\n   1.25790000e-01   1.58760000e-01   1.71200000e-01   2.99160000e-01\n   1.50100000e-02   1.11604000e+01   2.28760000e-01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-9616fc4755ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlinear_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CRIM\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ds100/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 482\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ds100/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/envs/ds100/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[  1.02330000e+01   6.71910000e-01   1.44550000e-01   1.11320000e-01\n   1.28020000e-01   8.01400000e-02   1.22358000e+00   3.56868000e+00\n   1.30580000e-01   1.42310000e-01   6.66400000e-02   8.66400000e-02\n   1.14600000e-01   2.77974000e+00   1.11081000e+01   7.99248000e+00\n   8.98296000e+00   6.12700000e-02   3.58090000e-01   6.71772000e+00\n   1.62864000e+00   5.66998000e+00   5.78900000e-02   3.83684000e+00\n   2.30040000e+00   1.77830000e-01   1.33598000e+01   2.50461000e+01\n   2.18700000e-02   1.90730000e-01   2.63630000e-01   1.10874000e+01\n   2.37934000e+00   4.20300000e-02   1.12658000e+00   6.23560000e-01\n   5.51500000e-02   3.55100000e-02   1.64390000e-01   2.92400000e+00\n   1.51902000e+00   3.15000000e-02   4.62960000e-01   7.89600000e-02\n   7.90410000e-01   4.75237000e+00   3.68940000e-01   1.44760000e-01\n   9.06000000e-03   9.26600000e-02   2.81838000e+00   3.84970000e+00\n   2.48017000e+01   2.98190000e-01   5.34120000e-01   5.11830000e-01\n   2.43938000e+01   4.87141000e+00   9.74400000e-02   4.01100000e-02\n   5.44520000e-01   4.89822000e+00   1.96570000e-01   3.87100000e-02\n   2.36482000e+01   1.03280000e-01   1.00840000e-01   5.30200000e-02\n   7.85700000e-01   8.82900000e-02   3.47428000e+00   6.07600000e-02\n   1.30100000e-02   1.34284000e+00   1.65660000e+00   5.42500000e-02\n   7.67202000e+00   8.30800000e-02   4.02020000e-01   2.24890000e-01\n   2.00849000e+01   2.11610000e-01   4.46200000e-02   1.75050000e-01\n   2.45220000e-01   1.80028000e+00   6.39312000e+00   5.56100000e-02\n   5.37200000e-02   3.76800000e-02   9.82349000e+00   2.15505000e+00\n   5.87205000e+00   2.36862000e+00   7.36711000e+00   4.29700000e-02\n   1.50380000e-01   2.07460000e-01   1.15040000e-01   4.09740000e+00\n   9.25200000e-02   9.60400000e-02   1.20830000e-01   1.70900000e-02\n   9.29900000e-02   1.00080000e-01   2.17700000e-02   3.39830000e-01\n   2.37857000e+00   3.53700000e-02   4.30100000e-02   5.11358000e+01\n   9.91655000e+00   1.96500000e-02   1.69020000e-01   5.47900000e-02\n   6.14700000e-01   1.20482000e+01   1.14250000e-01   8.81250000e-01\n   8.79212000e+00   7.88600000e-02   5.02300000e-02   8.89762000e+01\n   5.82401000e+00   5.20177000e+00   1.41030000e-01   8.19900000e-02\n   6.53876000e+00   1.36781000e+01   1.23290000e-01   5.78000000e-02\n   2.63548000e+00   2.49800000e-02   5.08300000e-02   4.83567000e+00\n   8.20058000e+00   3.31470000e-01   3.69200000e-01   2.24236000e+00\n   3.22640000e-01   4.66600000e-02   6.63510000e-01   5.75290000e-01\n   1.71340000e-01   6.89900000e-02   7.24400000e-02   3.15330000e-01\n   2.07162000e+01   6.15100000e-02   2.59150000e-01   1.09600000e-02\n   1.80846000e+01   1.31170000e-01   1.84982000e+01   7.52601000e+00\n   3.29820000e-01   1.35222000e+01   1.22690000e-01   1.78990000e-01\n   3.58400000e-02   1.50100000e-02   5.73500000e-02   1.02900000e-01\n   5.60200000e-02   1.58603000e+01   1.42502000e+00   9.37800000e-02\n   6.41700000e-02   7.72990000e-01   1.20742000e+00   3.32105000e+00\n   9.59571000e+00   2.89900000e-02   4.07710000e-01   1.22040000e-01\n   4.33700000e-02   1.13290000e-01   1.52880000e+01   9.18702000e+00\n   6.64200000e-02   1.27440000e-01   2.20511000e+01   5.29305000e+00\n   2.29690000e-01   6.12900000e-02   4.81900000e-02   1.08342000e+01\n   6.90500000e-02   1.53800000e-02   8.24809000e+00   1.48660000e-01\n   3.82140000e-01   1.00623000e+01   1.40520000e-01   1.22472000e+01\n   2.31390000e+00   8.18700000e-02   3.61500000e-02   1.98020000e-01\n   1.71710000e-01   2.29270000e-01   1.38799000e+00   5.78340000e-01\n   2.41030000e-01   1.77800000e-02   5.44114000e+00   9.55770000e-01\n   8.64476000e+00   5.37000000e-01   5.40110000e-01   4.59000000e-02\n   1.83377000e+00   9.33889000e+00   2.49800000e-01   1.10270000e-01\n   5.57780000e-01   3.25430000e-01   5.73116000e+00   2.11240000e-01\n   3.03470000e-01   1.30751000e+01   1.95100000e-02   4.41700000e-02\n   6.37960000e-01   2.44668000e+00   3.35900000e-02   1.78667000e+01\n   3.16360000e+00   1.19511000e+01   4.56000000e-02   2.10380000e-01\n   9.39063000e+00   1.09590000e-01   3.04100000e-02   5.20580000e-01\n   2.51990000e-01   2.17190000e-01   1.29320000e-01   6.65492000e+00\n   2.14090000e-01   2.79570000e-01   7.83932000e+00   1.00000000e-01\n   6.21100000e-02   9.06500000e-02   3.44500000e-02   1.46336000e+00\n   1.59360000e-01   7.01300000e-02   1.42362000e+01   9.06800000e-02\n   3.49400000e-01   6.56650000e-01   1.32620000e-01   4.98100000e-02\n   8.15174000e+00   2.73100000e-02   6.28807000e+00   1.50860000e-01\n   2.19770000e-01   1.18123000e+01   4.11300000e-02   1.36420000e-01\n   1.61282000e+00   8.49213000e+00   8.25260000e-01   3.76619000e+01\n   3.69695000e+00   3.93200000e-02   5.49700000e-02   1.43337000e+01\n   5.36000000e-02   3.11300000e-02   5.50070000e-01   1.06120000e-01\n   6.29760000e-01   2.53560000e-01   5.66000000e-02   2.25971000e+01\n   2.21880000e-01   2.01019000e+00   6.61700000e-02   2.39120000e-01\n   9.76170000e-01   7.50300000e-02   5.69175000e+00   4.75470000e-01\n   1.27570000e-01   1.36000000e-02   4.22239000e+00   8.87300000e-02\n   3.69311000e+00   8.44700000e-02   6.71800000e-01   8.37000000e-02\n   4.52700000e-02   5.82115000e+00   7.87500000e-02   2.44953000e+00\n   1.54450000e-01   2.53870000e-01   3.04900000e-02   3.30450000e-01\n   8.22100000e-02   8.52040000e-01   2.69380000e-01   6.80117000e+00\n   1.27346000e+00   1.04690000e-01   9.96654000e+00   6.91100000e-02\n   1.68118000e+01   8.26500000e-02   2.86558000e+01   2.54300000e-02\n   6.11540000e-01   4.92980000e-01   2.73397000e+00   3.40060000e-01\n   1.49632000e+00   4.26131000e+00   6.86000000e-02   8.26725000e+00\n   7.15100000e-02   7.75223000e+00   4.54400000e-02   2.89550000e-01\n   3.77498000e+00   7.16500000e-02   4.74100000e-02   1.25179000e+00\n   1.25790000e-01   1.58760000e-01   1.71200000e-01   2.99160000e-01\n   1.50100000e-02   1.11604000e+01   2.28760000e-01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "linear_clf.fit(X_train[\"CRIM\"], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.361313157240943"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(Y_train, linear_clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.361313157241"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse(predicted_y, actual_y):\n",
    "    return np.mean((predicted_y - actual_y)**2)\n",
    "\n",
    "train_error = mse(linear_clf.predict(X_train), Y_train)\n",
    "test_error = mse(linear_clf.predict(X_test), Y_test)\n",
    "train_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "test",
     "q03"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "q03 > Suite 1 > Case 1\n",
      "\n",
      ">>> np.allclose((train_error, test_error), (22.98349, 20.74714))\n",
      "False\n",
      "\n",
      "# Error: expected\n",
      "#     True\n",
      "# but got\n",
      "#     False\n",
      "\n",
      "Run only this test case with \"python3 ok -q q03 --suite 1 --case 1\"\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 0\n",
      "    Failed: 1\n",
      "[k..........] 0.0% passed\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving notebook... Saved 'lab11.ipynb'.\n",
      "Backup... 100% complete\n",
      "Backup successful for user: sungbin.andy.kang@berkeley.edu\n",
      "URL: https://okpy.org/cal/ds100/fa17/lab11/backups/Wn791v\n",
      "NOTE: this is only a backup. To submit your assignment, use:\n",
      "\tpython3 ok --submit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = ok.grade('q03')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "We have just executed a linear regression on our data. Can we get this predictor to be any better though? The following sections will go through cross-validation and some feature engineering in order to try and produce the best model with the least error.\n",
    "\n",
    "Let's start by seeing what is the **single** best feature for predicting boston house prices. For each feature in the given features list, fit a Linear Regression model to the training set where just that feature is selected for and check its accuracy on the validation set. Use the `mse` function you defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "features = boston_data.feature_names\n",
    "\n",
    "# Your code to find the single best feature\n",
    "...\n",
    "\n",
    "best_feature, best_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q04"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q04')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Folds Cross Validation\n",
    "\n",
    "We've so far been working with the generalized method of cross-validation where we split our data into a test and train set. Now let's try k-folds cross-validation to select the best subset of features for our model. Recall the approach looks something like:\n",
    "\n",
    "<img src=\"cv.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "For the sake of this lab, we have a provided a list of feature subsets and will try to find out which subset produces the best model predictor. In future assignments (Project 2?!?!), you will be given the full feature set and use EDA and other techniques you've learned in this class to select your set of best features.\n",
    "\n",
    "Here are the necessary steps to find your best linear predictor:\n",
    "\n",
    "1. Use the [`KFold.split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) function to get 4 splits on your training data. Note that `split` returns the indices of the data for that split.\n",
    "2. For each split, select out the rows and columns based on the split indices and features.\n",
    "3. Compute the MSE from your prediction.\n",
    "4. Based on the set with that gave the smallest MSE, choose your best set of features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "feature_sets = [['TAX', 'INDUS', 'CRIM'], ['RM', 'LSTAT', 'PTRATIO'], ['RM', 'B', 'NOX'], ['TAX', 'LSTAT', 'DIS']]\n",
    "\n",
    "kf = ...\n",
    "splits = \n",
    "\n",
    "def compute_error(train_idx, valid_idx, features):\n",
    "    '''\n",
    "    Splits the original training data based on the passed in indices.\n",
    "    Fits the data to the split's train set and returns the MSE \n",
    "    \n",
    "    Args:\n",
    "        train_idx (array): Indices of the split training data\n",
    "        valid_idx (array): Indicies of the split validation data\n",
    "        features (array): List of features (strings)\n",
    "\n",
    "    Returns:\n",
    "        Returns the MSE of predictions on the validation data\n",
    "    '''\n",
    "    return\n",
    "    \n",
    "# Your code to find the best feature set based on the error\n",
    "...\n",
    "        \n",
    "best_feature_set = ...\n",
    "best_feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q05"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q05')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "Finally, fit a linear classifier using your best feature set and predict housing prices for your original test set. Compute the final MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Fit your classifier\n",
    "...\n",
    "\n",
    "# Predict points from our test set and calculate the mse\n",
    "final_mse = ...\n",
    "final_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q06"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q06')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! You've used kfolds cross-validation to fit an accurate linear regression model to the dataset.\n",
    "\n",
    "In the future, you'd probably want to use something like [`cross_val_predict`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) to automatically perform cross-validation, but it's instructive to do it yourself at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Log into OkPy.\n",
    "# You might need to change this to ok.auth(force=True) if you get an error\n",
    "ok.auth(force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Run the cell below to run all the OkPy tests at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Running all tests...\")\n",
    "_ = ok.grade_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the cell below to submit your assignment to OkPy. The autograder should email you shortly with your autograded score. The autograder will only run once every 30 minutes.\n",
    "\n",
    "**If you're failing tests on the autograder but pass them locally**, you should simulate the autograder by doing the following:\n",
    "\n",
    "1. In the top menu, click Kernel -> Restart and Run all.\n",
    "2. Run the cell above to run each OkPy test.\n",
    "\n",
    "**You must make sure that you pass all the tests when running steps 1 and 2 in order.** If you are still failing autograder tests, you should double check your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
