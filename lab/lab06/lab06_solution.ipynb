{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6: Modeling and Estimation\n",
    "\n",
    "** If you are not attending lab, this assignment is due 10/03/2017 at 11:59pm (graded on accuracy) **\n",
    "\n",
    "** If you are attending lab, you do not need to submit the assignment; you just need to get checked off by your TA. **\n",
    "\n",
    "In this lab we will work through the process of:\n",
    "1. implementing a basic model, defining loss functions, \n",
    "1. minimizing loss functions using numeric libraries, and \n",
    "1. finally bootstrap sampling to understand the variability in the parameter estimates.\n",
    "\n",
    "This lab will continue using the toy tip calculation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "33c63379-d85b-4638-8183-d008fdb96de7",
    "_uuid": "7ad7f9f24df7dba8ac92d234890835f6b9970834",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# For instructor use only. Call this function to force refresh okpy tests\n",
    "def refresh():\n",
    "    import sys\n",
    "    keys = [k for k in sys.modules.keys() if 'ok_tests' in k]\n",
    "    for k in keys:\n",
    "        del sys.modules[k]\n",
    "    global ok\n",
    "    ok = Notebook('lab06.ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines load the tests.\n",
    "# !pip install -U okpy\n",
    "\n",
    "from IPython.display import display, Latex, Markdown\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('lab06.ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok.auth(force=True)\n",
    "ok.auth(force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Tips Dataset\n",
    "\n",
    "To begin with, we load the tips dataset from the `seaborn` library.  The tips data contains records of tips, total bill, and information about the person who paid the bill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sns.load_dataset(\"tips\")\n",
    "\n",
    "print(\"Number of Records:\", len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br></br>\n",
    "\n",
    "# Question 1: Defining the Model \n",
    "\n",
    "In lecture we modeled the percent tip.  In this lab we will instead attempt to model the tip value (in dollars) as a function of the total bill.  As a consequence we define the following mathematical model:\n",
    "\n",
    "$$\\Large\n",
    "\\texttt{Tip} = \\theta^*  \\times \\texttt{TotalBill}\n",
    "$$\n",
    "\n",
    "This follows the similar intuition that tips are some **unknown** percentage of the total bill.  We will then try to estimate the slope of this relationship which corresponds to the percent tip.\n",
    "\n",
    "Here the parameter $\\theta^*$ represents the true percent tip that we would like to estimate.  \n",
    "\n",
    "**Implement the python function for this model (yes this is very easy):**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def model(theta, total_bill):\n",
    "    \"\"\"\n",
    "    Takes the parameter theta and the total bill returns the computed tip.\n",
    "    \"\"\"\n",
    "    return theta * total_bill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q01a"
    ]
   },
   "outputs": [],
   "source": [
    "assert model(1.0, 2.0) == 2.0\n",
    "assert np.all(model(3.0, np.array([4.0, 5.0])) == 3.0 * np.array([4.0, 5.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br/><br/><br/>\n",
    "\n",
    "# Loss Functions\n",
    "\n",
    "In class we covered a range of different loss functions.  In this lab we will implement the squared loss and the absolute loss functions.  \n",
    "Suppose for a given total bill $x$ we observe a tip value of $y$ and our model predicts:\n",
    "$$\\Large\n",
    "% the \\hspace{0pt} is added to address a bug in safari mathjax\n",
    "\\hat{\\hspace{0pt}y} = \\theta * x\n",
    "$$ \n",
    "then any of the following might be appropriate **loss functions**\n",
    "\n",
    "1. **Squared Loss** (also known as the $L^2$ loss pronounced \"ell-two\"):\n",
    "$$\\Large\n",
    "% the \\hspace{0pt} is added to address a bug in safari mathjax\n",
    "L\\left(y, \\hat{\\hspace{0pt}y} \\right) = \\left( y - \\hat{\\hspace{0pt}y} \\right)^2\n",
    "$$\n",
    "1. **Absolute Loss** (also known as the $L^1$ loss pronounced \"ell-one\"):\n",
    "$$\\Large\n",
    "% the \\hspace{0pt} is added to address a bug in safari mathjax\n",
    "L\\left(y, \\hat{\\hspace{0pt}y} \\right) = \\left| y - \\hat{\\hspace{0pt}y} \\right|\n",
    "$$\n",
    "\n",
    "---\n",
    "<br></br>\n",
    "In this question, you are going to define functions for **squared loss** and **absolute loss**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2a: \n",
    "\n",
    "Implement the squared loss function:\n",
    "$$\\Large\n",
    "L\\left(y, \\hat{\\hspace{0pt}y} \\right) = \\left( y - \\hat{\\hspace{0pt}y} \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def squared_loss(y_obs, y_hat):\n",
    "    \"\"\"\n",
    "    y_obs: an array of observed valued\n",
    "    y_hat: an array of predicted values\n",
    "    \"\"\"\n",
    "    return (y_obs - y_hat)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q02a"
    ]
   },
   "outputs": [],
   "source": [
    "assert squared_loss(2, 1) == 1\n",
    "assert squared_loss(2, 0) == 4 \n",
    "assert squared_loss(5, 1) == 16\n",
    "assert np.sum((squared_loss(np.array([5, 6]), np.array([1, 1])) - np.array([16, 25]))**2) == 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2b:\n",
    "\n",
    "Suppose you observe $y=3.00$ and $x=28.00$ using the `model` and `squared_loss` function defined above plot the loss for a range of $\\theta$ values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array([3.00])\n",
    "x = np.array([28.00])\n",
    "thetas = np.linspace(0, 0.3, 200) # A range of theta values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "## Finish this by replacing 0.0 with the correct calculation \n",
    "loss = np.array([squared_loss(y, model(theta,x)).mean() for theta in thetas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q02b"
    ]
   },
   "outputs": [],
   "source": [
    "assert loss.dtype == np.dtype('float64') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following should produce this picture:\n",
    "\n",
    "![loss_curve.png](squared_loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "# Make the plot figure:\n",
    "plt.plot(thetas, loss, label=\"Squared Loss\")\n",
    "plt.xlabel(r\"Choice for $\\theta$\")\n",
    "plt.ylabel(r\"Loss\")\n",
    "plt.legend(loc=4)\n",
    "plt.savefig(\"squared_loss.png\",  bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2c:\n",
    "Implement the absolute loss \n",
    "$$\\Large\n",
    "L\\left(y, \\hat{\\hspace{0pt}y} \\right) = \\left| y - \\hat{\\hspace{0pt}y} \\right|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def abs_loss(y_obs, y_hat):\n",
    "    \"\"\"\n",
    "    y_obs: an array of observed valued\n",
    "    y_hat: an array of predicted values\n",
    "    return an array corresponding to the loss for each prediction\n",
    "    \"\"\"\n",
    "    return np.abs(y_obs - y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q02c"
    ]
   },
   "outputs": [],
   "source": [
    "assert abs_loss(2, 1) == 1\n",
    "assert abs_loss(-2, 1) == 3\n",
    "assert abs_loss(1, -3) == 4 \n",
    "assert np.linalg.norm(abs_loss(np.array([1,2]), np.array([-3,3])) - np.array([4, 1]), ord=1) == 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the plot of the absolute loss.  If you implemented things correctly it should look like:\n",
    "\n",
    "![absolute loss](absolute_loss.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "# This block is marked as solution to make sure that we generate the necessary plot\n",
    "y = np.array([3.00])\n",
    "x = np.array([28.00])\n",
    "thetas = np.linspace(0, 0.3, 200) \n",
    "\n",
    "loss = np.array([abs_loss(y, model(theta,x)).mean() for theta in thetas])\n",
    "\n",
    "plt.plot(thetas, loss, label=\"Absolute Loss\")\n",
    "plt.xlabel(r\"Choice for $\\theta$\")\n",
    "plt.ylabel(r\"Loss\")\n",
    "plt.legend(loc=4)\n",
    "plt.savefig(\"absolute_loss.png\",  bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 2d: Plotting **Average Loss** for our Data\n",
    "\n",
    "We can extend the above loss functions to an entire dataset by taking the average. Let the dataset $\\mathcal{D}$ be the set of observations:\n",
    "\n",
    "$$\\Large\n",
    "\\mathcal{D} = \\{(x_1, y_1), \\ldots, (x_n, y_n)\\}\n",
    "$$\n",
    "\n",
    "where $x_i$ is the total bill and $y_i$ is the tip dollar amount.\n",
    "\n",
    "We can define the average loss over the dataset as:\n",
    "\n",
    "$$\\Large\n",
    "L\\left(\\theta, \\mathcal{D}\\right) = \\frac{1}{n} \\sum_{i=1}^n L(m_\\theta(x_i), y_i) = \\frac{1}{n} \\sum_{i=1}^n L(\\theta *  x_i, y_i)\n",
    "$$\n",
    "\n",
    "where $m_\\theta(x_i) = \\theta * x_i$ is the model evaluated using the parameters $\\theta$ on the bill amount $x_i$.\n",
    "\n",
    "**Complete the following code block to render a plot of the average absolute and squared loss for different values of $\\theta$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "thetas = np.linspace(0, 0.3, 200) # A range of theta values:\n",
    "y = data['tip']\n",
    "x = data['total_bill']\n",
    "\n",
    "avg_squared_loss = np.array([squared_loss(model(theta, x), y).mean() for theta in thetas])\n",
    "avg_absolute_loss = np.array([abs_loss(model(theta, x), y).mean() for theta in thetas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If done correctly the following plot should look like:\n",
    "\n",
    "![Average Loss](average_loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "plt.plot(thetas, avg_squared_loss, label = \"Average Squared Loss\")\n",
    "plt.plot(thetas, avg_absolute_loss, label = \"Average Absolute Loss\")\n",
    "plt.xlabel(r\"$\\theta$ Value\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.savefig(\"average_loss.png\",  bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br/><br/><br/> \n",
    "\n",
    "# Question 3: Minimizing The Loss\n",
    "\n",
    "In some cases, it is possible to use calculus to analytically compute the parameters $\\theta$ that minimize the loss function.  However, in this lab we will use computational techniques to minimize the loss.  Here we will use the [`scipy.optimize.minimize`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) routine to minimize the average loss.\n",
    "\n",
    "Complete the following python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def minimize_average_loss(loss_function, model, x, y):\n",
    "    \"\"\"\n",
    "    loss_function: either the squared or absolute loss functions from above.\n",
    "    model: the model (as defined above)\n",
    "    x: the x values (total bills)\n",
    "    y: the y values (tip amounts)\n",
    "    return the estimate for theta as a scalar\n",
    "    \n",
    "    Note we will ignore failed convergence for this lab ... \n",
    "    \"\"\"\n",
    "    return minimize(lambda theta: loss_function(model(theta, x), y).mean(), x0=0.0)['x'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Should be roughly 0.1437\n",
    "y = data['tip']\n",
    "x = data['total_bill']\n",
    "minimize_average_loss(squared_loss, model, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Should be roughly 0.1496\n",
    "y = data['tip']\n",
    "x = data['total_bill']\n",
    "minimize_average_loss(abs_loss, model, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q03"
    ]
   },
   "outputs": [],
   "source": [
    "y = data['tip']\n",
    "x = data['total_bill']\n",
    "assert np.isclose(minimize_average_loss(squared_loss, model, x, y), 0.14373189229218733)\n",
    "assert np.isclose(minimize_average_loss(abs_loss, model, x, y), 0.14958862353611219)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br/><br/><br/> \n",
    "\n",
    "# Question 4: Simulation\n",
    "\n",
    "In this question we will use the bootstrap procedure to estimate the distribution of loss minimizing estimators.  \n",
    "\n",
    "At a high level the bootstrap algorithm is:\n",
    "\n",
    "```\n",
    "samples = []\n",
    "\n",
    "for i in nsamples:\n",
    "\n",
    "    n = len(data)\n",
    "\n",
    "    data_sample = draw sample n samples WITH REPLACEMENT from the data (both x and y)\n",
    "    \n",
    "    sample_theta_opt = estimate theta on data_sample\n",
    "    \n",
    "    samples.append( sample_theta_opt )\n",
    "    \n",
    "\n",
    "sns.distplot(samples)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4a \n",
    "\n",
    "To use `bootstrap`, we need to repeatedly draw samples. We give you the code for the bootstrap:\n",
    "\n",
    "```python\n",
    "def bootstrap(loss_function, model, x, y, nsamples=1000):\n",
    "    samples = []\n",
    "    for i in range(nsamples):\n",
    "        samples.append(sample_theta(loss_function, model, x, y))\n",
    "    return samples \n",
    "```\n",
    "\n",
    "However, you will need to implement the `sample_theta()` function which should:\n",
    "\n",
    "1. resample the data with replacement.\n",
    "    * **hint 1:** check out [`np.random.randint`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.randint.html)\n",
    "    * **hint 2:** consider something like:\n",
    "        ```python\n",
    "        x = np.array([1,2,3])\n",
    "        y = np.array([1,2,3])\n",
    "        ind = np.random.randint(0, 3, 3)\n",
    "        print(x[ind], y[ind])\n",
    "        ```\n",
    "1. call the loss minimization routine (from above) to estimate $\\theta$ on the sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "def sample_theta(loss_function, model, x, y):\n",
    "    \"\"\"\n",
    "    loss_function: either the squared or absolute loss function\n",
    "    model: the predictive model as defined above\n",
    "    x: the total bill as defined above\n",
    "    y: the tip value as defined above\n",
    "    returns a single theta estimate for a random resampling of the data \n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    ind = np.random.randint(0, n, n)\n",
    "    return minimize_average_loss(loss_function, model, x[ind], y[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bootstrap(loss_function, model, x, y, nsamples=1000):\n",
    "    samples = []\n",
    "    print_mod = int(nsamples/10.0)\n",
    "    for i in range(nsamples):\n",
    "        if (i+1) % print_mod == 0:\n",
    "            print(\"Generating Sample\", i+1, \"out of\", nsamples, \"samples.\")\n",
    "        samples.append(sample_theta(loss_function, model, x, y))\n",
    "    return samples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4b \n",
    "\n",
    "Using `bootstrap()` function to generate 1000 samples for **squared loss** and **absolute loss**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapped Squared Loss\n",
    "\n",
    "Call the above `bootstrap` function using the `squared_loss`, `model`, `x`, and `y` for 1000 samples.  This may take up to a minute to complete.  If you are debugging your implementation you may try running fewer samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "y = data['tip']\n",
    "x = data['total_bill']\n",
    "squared_loss_samples = bootstrap(squared_loss, model, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If done correctly the following plot should **approximately** look like:\n",
    "\n",
    "![squared_loss_samples](squared_loss_samples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapped Absolute Loss \n",
    "\n",
    "Call the above `bootstrap` function using the `absolute_loss`, `model`, `x`, and `y` for 1000 samples.  **This may take a few minutes to complete.**  If you are debugging your implementation you may try running fewer samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "y = data['tip']\n",
    "x = data['total_bill']\n",
    "abs_loss_samples = bootstrap(abs_loss, model, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If done correctly the following plot should **approximately** look like:\n",
    "\n",
    "![abs_loss_samples](abs_loss_samples.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(abs_loss_samples)\n",
    "plt.xlabel(r\"Estimated $\\theta$\")\n",
    "print(\"Sample SD:\", np.std(abs_loss_samples))\n",
    "print(\"Sample MEAN:\", np.mean(abs_loss_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4c:\n",
    "\n",
    "Which loss function has lower variability and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "question4c_answer = \"\"\"\n",
    "The absolute loss has lower variability as it is less sensitive to extreme tip values.  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Congrats! You are finished with this assignment. For convenience, we've included a cell below that runs all the OkPy tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Running all tests...\")\n",
    "_ = [ok.grade(q[:-3]) for q in os.listdir(\"ok_tests\") if q.startswith('q')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the cell below to submit your assignment to OkPy. The autograder should email you shortly with your autograded score. The autograder will only run once every 30 minutes.\n",
    "\n",
    "**If you're failing tests on the autograder but pass them locally**, you should simulate the autograder by doing the following:\n",
    "\n",
    "1. In the top menu, click Kernel -> Restart and Run all.\n",
    "2. Run the cell above to run each OkPy test.\n",
    "\n",
    "**You must make sure that you pass all the tests when running steps 1 and 2 in order.** If you are still failing autograder tests, you should double check your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "301px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}